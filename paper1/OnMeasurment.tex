\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amssymb, physics, geometry, mdframed, authblk}
\usepackage{xcolor}
\usepackage{microtype}
\usepackage{booktabs}
\usepackage[hidelinks]{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{mathrsfs}
\geometry{margin=1in}

\title{On Measurement: The Relativity of Information Frames}
\author[ ]{Gabriel Masarin}
\affil[ ]{\texttt{g.masarin@proton.me}}
\date{}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\usepackage{setspace}
\setstretch{1.07}
\clubpenalty=10000
\widowpenalty=10000
\setlength{\belowdisplayskip}{0.8\baselineskip}
\setlength{\abovedisplayskip}{0.8\baselineskip}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newmdenv[
  backgroundcolor=gray!10,
  linecolor=gray!50,
  linewidth=1pt,
  roundcorner=6pt,
  innertopmargin=8pt,
  innerbottommargin=8pt,
]{principlebox}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheoremstyle{axiomstyle}% <name>
  {8pt}% <Space above>
  {8pt}% <Space below>
  {\itshape}% <Body font>
  {}% <Indent amount>
  {\bfseries}% <Theorem head font>
  {.}% <Punctuation after theorem head>
  {0.5em}% <Space after theorem head>
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}% <Theorem head spec>

\theoremstyle{axiomstyle}
\newtheorem{axiom}{Axiom}
\begin{document}
\maketitle

\vspace{0.5em}
\begin{abstract}

\end{abstract}

\section{Introduction}

\section{Motivation - The Relativity of Information Frames}

Consider two physical observers, Alice and Bob, each equipped with a clock and a ruler.
To infer a particle’s momentum, they make two position measurements and record 
the elapsed time.

However,
\begin{itemize}
    \item If they agree on the spatial separation, they must disagree on the elapsed time;
    \item If they agree on the elapsed time, the measured spatial separation must differ.
\end{itemize}

Their interactions with the world differ — and so does what each can resolve as an event.

What Alice calls “particle at position $x$ at time $t$” is determined by her 
interaction channels and detection thresholds.

Thus there is no global, frame-independent $\sigma$-algebra of events.  
Every physical system carries its own information frame: a $\sigma$-algebra 
of distinguishable outcomes accessible through its interactions.

Einstein taught that coordinate descriptions are relative while causal order is invariant.  
We extend this principle.

\begin{principlebox}
\begin{center}
\textbf{Relativity of Information Frames (RIF)}

Nature does not privilege one information frame over another. What is physical is what
all information frames can agree upon.
\end{center}

\end{principlebox}

Measurement is not the revelation of a pre-existing global state; it is the joint refinement
(and, when necessary, coarse-graining) of information frames when systems interact.  
From this symmetry, quantum state update, pointer bases, and even causal 
geometry follow as consequences.

\section{Background}
\subsection{Measure Theory}
The complete introduction to the richness of measure theory probability theory 
is not in the scope of this work, we refer to \cite{Williams1991} for that, 
we will at least the concept of probability space. We hope the work is understandable with
only this crude introduction but familiarity with the subject is advised.

\subsubsection*{Probability Spaces}
In measure theoretical probability, a probability space consists of a triplet 
$(\Omega, \mathcal F, \mu)$. Each piece represents a core element of a probality model.
\subsubsection*{The Sample Space $\Omega$}
The sample space $\Omega$ represents all events that can happen. It is often not defined
to be something in particular. Simply a space where we can draw samples $\omega \in \Omega$
from.

It can be seen as particular realizations of an experiment, or trials of a coin toss or
observations of a particular population model.
\subsubsection*{The $\sigma$-algebra $\mathcal F$}
A $\sigma$-algebra represents the set of events the model view as possible. It can be seen
as what can happen in the probability model. Events are are sets composed of samples 
$\omega \in \Omega$.

Events are described by $\sigma$-algebras. They are a set of subsets of $\Omega$ with
the following properties:
\begin{definition}[$\sigma$-algebra]
    A $\sigma$-algebra $\mathcal F$ is a family of subsets of $\Omega$ with the following
    properties:
    \begin{enumerate}
        \item $\empty,\Omega \in \mathcal F$
        \item Closed under complemetns. $F \in \mathcal F \rightarrow F^{c} \in \mathcal F$
        \item Closed under countable unions. 

            \[\left\{F_i\right\}_{i \in \mathbb N} \in \mathcal F \rightarrow 
            \bigcup_{i \in \mathbb N} F_i \in \mathcal F\]
    \end{enumerate}
    
\end{definition}
The $\sigma$-algebra is the central object of this framework. They represent what is 
possible for a given probability space.
\subsubsection*{The Probability Measure $\mu$}
A probability measure is a function that assigns values in $[0,1]$ to events in the
$\sigma$-algebra $\mathcal F$, with the following additional requirements:
\begin{definition}[Probability Measures]
    A probability measure $\mu: \mathcal F \to [0,1]$ is a function with the following
    properties:
    \begin{enumerate}
        \item Total probabilities:
            \[
                \mu(\emptyset) = 0 \quad \mu(\Omega) = 1
            \]
        \item For any collection of disjoint sets $\left\{F_i\right\}_{i \in \mathbb N}$,
            with $F_i \cap F_j = \emptyset$ for all $i \neq j$.
            \[
                \mu\left(\bigcup_{i \in \mathbb N} F_i\right) = 
                \sum_{i \in \mathbb N} \mu(F_i)
            \]
    \end{enumerate}
For this work, probability measures can be seen as states on the probability space. How
a particular sigma algebra is distributed in a particular scenario.
\end{definition}
\subsubsection*{Measurable Functions}
A \textbf{measurable function}, often also called a \textbf{random variable} is a function
between probability spaces $f: \Omega_1 \to \Omega_2$ with the following property:
\[\
    \forall A \in \mathcal F_2\; \longrightarrow\; f^{-1}(A) \in \mathcal F_1
\]
That is, it takes measurable sets from $\mathcal F_2$ to measurable sets in $\mathcal F_1$.
\subsubsection*{Pushfoward Measure}
When we have a measurable function $f: \Omega_1 \to \Omega_2$ and a probability measure
$\mu$ in $\Omega_1$, we can define a probability measure in $\Omega_2$ as:
\[
    \left(\mu f\right)(A) = \mu\circ f^{-1}(A) \quad A \in \mathcal F_2
\]
It represents how the probability measure in $\Omega_1$ measures the corresponding
events of the random variable $f$.
\subsubsection*{Embeddings}
There are a few special measurable functions we will be interested in. The first defines
a full \textbf{isomorphism} of spaces:
\begin{definition}[Measurable Isomorphism]
    A measurable function $T: \Omega_1 \to \Omega_2$ that is \textbf{bijective} and whose
    inverse $T^{-1}: \Omega_2 \to \Omega_1$ is also measurable defines a \textbf{isomorphism}
    of probability spaces:
    \[
        \left(\Omega_1, \mathcal F_1\right) \cong \bigl(\Omega_2, \mathcal F_2\bigr)
    \]
\end{definition}
Naturally such bijections form a group:
\begin{definition}[Measurable Space Automorphisms]
\[
    \text{Aut}_{\Omega,\mathcal F} := \left\{T: \Omega \to \Omega 
    \text{ is bijective, } T\text{ and }T^{-1}\text{ are measurable }\right\}
\]
\end{definition}
These maps preserve the full structure of the measurable space, for our work we will need
a class that still preserves structure but can embed the measurable space into a larger
one.
\begin{definition}[Measurable Embedding]
    A measurable embedding $\iota: \Omega_1 \to \Omega_2$ is a \textbf{injective} measurable
    function with a measurable inverse. It can also be seen as a local homomorphism.
\end{definition}
These embeddings preserve the $\sigma$-algebra of the source space entirely in the target
space.
\subsection{Contextuality}
The first important concept the theory relies upon is that of contextuality. All our
definitions here are translated from the \cite{Abramsky&Brandenburger} contextuality
in sheaf-theory. They have been adapted to a measure theory framework.
\subsubsection*{Labels and Contexts}
First we look at the definition of a measurement label. A measurement label intuitively
represents what one can tell apart, that is what questions a system can ask. It can be
seen as the fundamental degrees of freedom of a given model. 
\subsubsection*{Measurement Labels}
\begin{definition}[Measurement labels]
    A measurement label is an abstract symbol $m$ that identifies a physical distinction
    we may attempt to extract from the system. Together with its outcome 
    space $(\Omega_m, \mathcal F_m)$. That is:
    \[
        m \to (\Omega_m, \mathcal F_m)
    \]
    The set of all measurement labels the model considers primitive is called $\mathcal M$.
\end{definition}

Then naturally, our global space, where all measurament labels exist is then:
\begin{definition}[Global Space]
    The global space, the space of all degrees of freedom and all their distinctions is 
    \[
        \left(\Omega_{\mathcal M}, \mathcal F_{\mathcal M}\right) = 
        \left(\prod_{m \in \mathcal M} \Omega_m \;, \bigotimes_{m \in \mathcal M} 
        \mathcal F_m \right)
    \]
    \noindent
    Where $\mathcal F_1 \otimes \mathcal F_2 = 
    \sigma\left(\left\{F_1 \times F_2: F_1 \in \mathcal F_1, F_2 \in 
    \mathcal F_2\right\}\right)$. We note that, we do not define a particular probability measure on this space, that
    is because what we are interested in at the moment is the structure of the space,
    not a specfic measure on it.
\end{definition}

\subsubsection*{Contexts}
Next we talk about contexts. Contexts are given by the subset of labels or degrees of
freedom a given observer cares about something he is interacting with. It can be seen
as the fundamental set of questions he can ask about the part of the model he interacts 
with.

\begin{definition}[Context]
    A context $C \subseteq \mathcal M$ is a finite collection of 
    measurement labels that are jointly meaningful. 
    To each context we associate a measurable space:
    \[
        (\Omega_{C}, \mathcal F_{C}) := \left(\prod_{m \in C}
        \Omega_m \;, \bigotimes_{m \in C} \mathcal F_m \right)
    \]
\end{definition}

Within a context we also define the projections:
\begin{definition}[Canonical Context Projections]
    The projections for a context $C$ are defined as \textbf{measurable functions} from a
    context to one of its label spaces.
\[
    \pi_{C \to \{m\}}: \Omega_C \to \Omega_m
\]
With:
\[
    \pi_{C \to \{m\}}\left(\omega\right) = \omega_m \quad \forall \omega \in C
\]
\noindent
That is, the projections map to the context corresponding to the label $m$ within
the context $C$. The extension to a subcontext $D \subseteq C$ is naturally
$\pi_{C\to D}$.
\end{definition}
Intuitively projection can be seen as the \textbf{perspective} $C$ has on $m$. 
For context projection we will also need its inverse definition.
\begin{definition}[Cylinder Embedding]
    For every outcome $\omega_1 \in \Omega_m$ we embed it in the context space 
    $(\Omega_C,\mathcal F_C)$. This gives the definition:
    \[
        \pi_{C\to\{m\}}^{-1}(A) := \left\{\omega \in \Omega_C:\; x_m \in A\right\}
    \]
    \noindent
    Since $\pi$ is a measurable function by definition $\pi_{C\to\{m\}}^{-1}(A) \in 
    \mathcal F_C$.
\end{definition}

We importantly note that, a context require $\pi$. They tell the context where its events
come from. In principle, a context does not hold \textbf{information that comes from nowhere.}

\subsubsection*{Empirical Model}
We will now introduce the first concept that requires the use of specific probability 
measures that is the definition of an \textbf{empirical model}. 

Intuitively can be seen as a particular realization of the model, or a 
particular realization of a \textbf{perspective} on the underlying world. 
We can also think of it as a particular family of \textbf{coodinates} in the probability 
spaces of the contexts.
\begin{definition}[Empirical model]
    An \textbf{empirical model} is a family $\left\{e_C \right\}_{ C \in \mathcal M}$ 
    of probability measures on $\left(\Omega_C, \mathcal F_C\right)$. 
    For all $C,C' \in \mathcal M$ and all $D \in C \cap C'$ we have:
    \[
        \left(\pi_{C \to D}\right)_* e_C \; = \; \left(\pi_{C' \to D}\right)_* e_{C'}
    \]
    This condition means that on overlaps, the probability measures must agree. They
    come from the same underlying labels.
\end{definition}

\subsubsection*{Contextuality}
The empirical families allows us to define what will be the driving feature of our 
framework. It is the defintion of \textbf{Contextuality}. When \textbf{perspectives} 
only completly exist on the context they came from.

\begin{definition}[Contextuality]
    The family $\left\{e_{E} \right\}_{ E \in \mathcal M}$ is called contextual 
    in $\mathcal M$ if no probability measure $\mu$ on the global space $\mathcal M$ 
    exists satisfying:
    \[
        \left(\pi_{C \to E}\right)_* \mu \; = e_{E} \quad \forall E \subset \mathcal M
    \]
    \noindent
    They are called non-contextual, if such probability measure exists.
\end{definition}

Intuitively, it means that in that shared space, the questions still make perfect sense
together if they are non-contextual. We know exactly where they came from.

If they are contextual then there is no way to pick a coordinate, or probability measure
on the global space that agrees with all probabilities the contexts of that space found.

The core feature we will need here is that, there exists experiments or real situations
where the global space is contextual this fact can be seen in depth in 
\cite{Abramsky&Brandenburger}. This particular definition, is of probabilistic 
contextuality as defined on \cite{Abramsky&Brandenburger}.
\section{Structural Contextuality}
To get a better understanding on RIF we need to look at other formulations of 
contextuality. We want to understand contextuality without particular probability 
distributions.


For this, we adapt the sheaf like condition, than just the failure of probabilities to
have the correct marginals, this in particular matches the \textbf{strong contextuality} 
defined in \cite{Abramsky&Brandenburger}. First we define a \textbf{Information Frame}.

\begin{definition}[Information Frame]
    A information frame is a probability space over a context $C \subseteq \mathcal M$ 
    with a particular event algebra 
    $\mathcal F \subseteq \bigotimes_{m \in C} \mathcal F_m$ corresponding to the set
    of distinctions that frame can see about the labels $m$.
    \[
        \mathscr I_{C, \mathcal F} := \left(\prod_{m \in C} \Omega_m, \mathcal F\right)
    \]
    \noindent
    A information frame could be seen as a perspective on the world. A view of what it
    can in principle see about a system. A probability measure there represents a 
    particular state of the world. For notation convinience we will use 
    $\mathscr I_1 = \mathscr I_{C1, \mathcal F_1}$
\end{definition}

In general, Information Frames are defined on the support of some probability measure,
meaning we get rid of events that a context does not see as possible.

An important piece we have in such spaces are shared events. We will often refer to shared
events $E$ as follows:
\begin{definition}[Shared Event]
    We call an event $E$ a shared event of contexts $C$ and $C'$ when $C\cap C' = L \neq 
    \emptyset$, the shared labels, and $E$ is a event only on those labels.

    Then we can define, using the \textbf{Cylinder embeddings}:
    \[
        E_1 = \pi_{C\to L}^{-1}(E) \quad E_2 = \pi_{C'\to L}^{-1}(E)
    \]
    We will often write $E \in \mathcal F_C \cap F_{C'}$, and even treat $E$ as an event
    in those algebras. But it always corresponds to the events of the \textbf{Cylinder 
    embedding}.
\end{definition}
We can now do a definition of contextuality based only on the structure of the 
$\sigma$-algebras.
\begin{definition}[Structural Contextuality]
    Given a family of contexts $\mathcal C$ of $\mathcal M$ and corresponding 
    information frames $\mathscr I_{C, \mathcal F_C}$ and a global space 
    $\left(\Omega, \mathcal F\right)$. 

    The family is said to be \textbf{structuraly non-contextual} if there is a family of 
    corresponding \textbf{embeddings} and some sub-$\sigma$-algebra 
    $\mathcal G \subseteq \mathcal F$ such that:
    \[
        \iota_{C \in \mathcal C}: \mathscr I_{C, \mathcal F_C} \to 
        \left(\Omega, \mathcal G\right)
    \]
    Such that for every pair $C,C'$ and every event 
    $E \in \mathcal F_C \cap \mathcal F_{C'}$, that is events on shared labels, we have:
    \[
        \iota_C(E) = \iota_{C'}(E)
    \]
    Formally, for $L = C\cap C'$ that requires:
    \[
        \iota_C(\pi_{C\to L}^{-1}(E)) = \iota_{C'}(\pi_{C\to L}^{-1}(E))
    \]
    \noindent
    If no such embedding exists then the family is called \textbf{structuraly contextual}.
\end{definition}

The existence of \textbf{strong contextuality} as seem in \cite{Abramsky&Brandenburger} 
guarantees structural contextuality also exists, in particular the results in 
\cite{Kochen-Specker} show that, if we try to keep the full $\sigma$-algebra 
event structure, structural contextuality will eventually happen. This 
shows contextuality is essentially inevitable in sufficiently complex logics.

In general, in the product space, this can be seen as the failure of cylinder sets to hold
all the complexity of all frames event structure. We can think of this in the simple case
of two frames. Consider:
\[
    \iota_1(x) = (x, f(x)) \quad \iota_2(y) = (g(y), y) 
\]
Here we simply represent the embedding as the identity on the labels it controls, that
forces part of the embedding structure, the other part, corresponding to labels the original
space does not see, is free to be any measurable function.

The issue is when the events have non-trivial intersections. It is not always possible to
match the functions and identity correctly that is precisely 
\textbf{structural contextuality}.
\section{The Relativity Of Information Frames}
\subsection{Interaction}
Now we work on making precise the meaning of the \textbf{Relativity of Information Frames
(RIF)}. To do so, the central objects of study will be \textbf{Information Frames} as
in defintion 4~.1. Information frames are the only ontic objects in this theory, 
everything works on their interactions.

We now turn our attetion to making the definition of interaction precise. 
The first step is to define the \textbf{Joint Frame}. A information frame where 
the interaction takes place. Before this we will note that when we write:
\[
    \iota(\mathcal F_C) := \mathcal G 
\]
That is, there is some sub-$\sigma$-algebra $\mathcal G$ on the codomain where that
embedding exits. We also note that there can be many such embeddings. 
These differences are not of particular interest to us, they are related 
by the automorphism symmetry defined in Definition~3.7, so we can treat them as equivalent.
\begin{definition}[Joint Frame]
    Given a family of information frames $\left\{\mathscr I_i\right\}_{i \in I}$ we 
    can construct their joint frame as:
    \[
        \mathcal J_{I} :=\left( \Omega_{\mathcal J_I},\; \mathcal F_{\mathcal J_I}\right) 
        := \left(\prod_{m \in \{\bigcup_{i \in I}C_i \subseteq \mathcal M\}}
            \Omega_{m},\; 
        \bigotimes_{i \in I}\iota_i\left(\mathcal F_i\right)\right)
    \]
    \noindent
    The space that hold all distinctions of all information frames.
\end{definition}
While such a frame is always definable, contextuality tells us it is not always possible
to assign it a probability measure that is consistent with the frames that generated it.

Structural contextuality tells us when it is impossible to make a non-contextual 
joint frame. Furthermore, indentification of events becomes difficult, there can be 
different events with the same "shadow". In particular, shared events are events we
want to identify as the same, but in contextual cases in the joint space, we can't.

One important thing to note however, is that once we generate such a joint space, the 
embeddings are fixed, we are not allowed to change embeddings midway. While embeddings
can be different, the only the part that preserves the $\sigma$-algebra 
structure of it's frame is of relevance to us, so all embeddings can be treated as the
same.
\subsection{The Structure of the contexts}
To make our realitivity principle precise we need a way to compare the structure of contexts 
in the joint frame.The problem is once we fix a joint frame $\mathcal J_I$ through some 
family of embeddings $\iota_{i \in I}$ we still can't properly compare the contexts as
they do not live in the global space.

A way to do this is to consider the following map
\begin{definition}[Local Projections]
Given a family of embeddings $\iota_i$ that generated a particular frame $\mathcal J_I$.
The local projections $e_i$ are
\[
    e_i := e_{C_i} := \left( \iota_i\circ \pi_{\mathcal J_I \to C_i}\right): 
    \Omega_{\mathcal J_I} \to \Omega_{\mathcal J_I}
\]
\end{definition}
These $e_{i}$ represent the full event structure of the frame $\mathscr I_i$ in the joint
frame. They can also be seen as \textbf{idempotent coarse-graining maps}, looking from 
the perspective of a given context at an event.
\subsection{The Symmetry Of Information}
\subsubsection*{Privilege}
We are finally ready to introduce the concept of 
\textbf{The Relativity of Information Frames}.
We begin with the definition of \textbf{Privilege} in a \textbf{Joint Frame}.
\begin{definition}[Privilege]
    We say a joint frame $\mathcal J_{I}$ privileges $\mathscr I_1$ over $\mathscr I_2$ 
    for some event $E \in \mathcal F_{\mathcal J_I}$ if, 
    for its local projections $e_1,e_2$ we have:
    \[
        e_2(E) \neq e_2(e_1(E))
    \]
\end{definition}
Basically we say that the joint frame privileges $\mathscr I_1$ over $\mathscr I_2$ if the 
local projection of $\mathscr I_1$ changes what $\mathscr I_2$ sees. 
That is, coarse-graining through $\mathscr I_1$ perspectives alters $\mathscr I_2$
perspective.

In particular, its worth noting that the local projections do not commute
when privilege happens:
\[
    e_1 \circ e_2(E) \neq e_2 \circ e_1(E)
\]
We also note that, if $\mathscr I_1$ is privileged over $\mathscr I_2$ on event $E$, 
it is still possible for $\mathscr I_2$ to be privileged over $\mathscr I_1$ on $E$. This is 
a bidirectional definition despite the name somewhat implying a ordering structure.
\subsubsection*{The Relativity of Information Frames}
We can now state the relativity of information frames precisely.
\begin{axiom}[The Relativity Of Information Frames]
    After interaction, a event is physically admissible if and only if it does not privilege
    one information frame over another. Equivalently, in the physically admissible joint
    frame, no information frame is privileged over another for any event in its 
    $\sigma$-algebra.
\end{axiom}

More explicitly for any pair of frames $i,j$ of the joint frame and any shared event $E$
we have:
\[
    e_i(E) = e_i(e_j(E))\quad \text{ and }\quad e_j(E) = e_j(e_i(E))
\]
That is, the set of physical events is:
\[
    \mathcal F^{\text{phys}} := \left\{E \in \mathcal F_{\mathcal J_I} \mid 
    e_{i}\circ e_j(E) = e_i(E) \quad \forall \mathscr I_i,\mathscr I_j\right\}
\]
\begin{proposition}
    The sets in $\mathcal F^{\text{phys}}$ form a $\sigma$-algebra.
\end{proposition}
\begin{proof}
    If $E \in \mathcal F^{\text{phys}}$ then, for every $i,j$:
    \[
        e_i(e_j(E^c)) = e_i(e_j(E)^c) = e_i(e_j(E))^c = e_i(E)^c = e_i(E^c)
    \]
    So $E^c \in \mathcal F^{\text{phys}}$.

    And let $E_n$ be a countable collection of RIF-valid events, that is:
    \[
        e_i(e_j(E_n)) = e_i(E_n) \quad \forall n,i,j
    \]
    Since:
    \[
        e_i\left(\bigcup_n E_n\right) = \bigcup_n e_i(E_n)
    \]
    Given any $i,j \in I$ we have:
    \[
        e_i\left(e_j\left(\bigcup_n E_n\right)\right) = e_i\left(\bigcup_n e_j(E_n)\right) 
        = \bigcup_n e_i \circ e_j (E_n) = \bigcup_n e_i(E_n) = e_i\left(\bigcup_n E_n\right)
    \]
\end{proof}
To match quantum mechanics we will call this $\sigma$-algebra the \textbf{pointer algebra}.
\begin{definition}[Pointer Algebra]
    The algebra of physically admissible events is called the pointer algebra.
    \[
        \mathcal F_{\text{ptr}} = \mathcal F^\text{phys}
    \]
\end{definition}
\subsection{Relation to Contextuality}
Now we prove a few important properties of the pointer algebra. We already saw how closely
related to contextuality the pointer algebra is, that is RIF fails exactly when 
contextuality is present.

First we show that, when a joint frame with the pointer algebra is defined, we have a
particular type of non-contextuality. It is important to note here, that our structural
contextuality definition no longer applies. This is because after throwing away events
we no longer have embeddings, the maps there might be many to one. So for this we equip
the information frames with \textbf{empirical probability families}, and show that we
can construct a well behaved measure on the \textbf{joint pointer frame}.
\begin{lemma}[The Joint Pointer Frame is non-contextual]
    Let $\left\{\mu_i\right\}_{i \in I}$ be a \text{empirical family} on the contexts of
    the information frames $\left\{\mathscr I_i\right\}_{i \in I}$, then there exists
    a probability measure $\mu$ in the \textbf{Pointer Joint Frame} such that:
    \[
        \mu(E) = \mu_i(\pi_{\mathcal J_I \to \mathcal C_i}(E))
    \]
    For every event $E$ and every choice of $i$.
\end{lemma}
\begin{proof}
For some $i \in I$ and for each $E \in \mathcal F_{\text{ptr}}$, define:
\[
    \mu(E) := \mu_i(\pi_i(E))
\]
Let $E \in \mathcal F_{\text{ptr}}$ and let $C_j$ be some other context. If 
$C_j\cap C_i = \emptyset$, no consistency condition is required.
If $C_j\cap C_i \neq \emptyset$ RIF implies that either both are trivial or they have
the exact same projection onto $C_i \cap C_j$. In the later case the consistency conditions
imply:
\[
    \mu(E) = \mu_i(\pi_i(E)) = \mu_j(\pi_j(E))
\]
So $\mu$ is a consistent probability measure on the joint pointer frame.
\end{proof}
We now see that, for contextual families, RIF is not satisfied.
\begin{proposition}[Contextuality violates RIF]
    If a family of contexts given by $I$ is \textbf{structurally contextual}. 
    Then the naive joint frame $\mathcal J_I$ violates RIF for some event.
\end{proposition}
\begin{proof}
    For simplicity consider only two frames that disagree.
    We know there is a shared event $E$ for which
    \[
        \iota_1(\pi_1(E)) \neq \iota_2(\pi_2(E))
    \]
    Now let $A = \iota_1(\pi_1(E))$ and $E = \iota_2(\pi_2(E))$. This makes it clear
    that:
    \[
        \pi_2(E) \neq \pi_2(A)
    \]
    Since otherwise, because the embeddings are injective we would have $A = E$. This 
    already implies:
    \[
        e_2 \circ e_1(E) \neq e_2(E)
    \]
    So RIF is violated for the event $E$.
\end{proof}
Now we show that, using a larger $\sigma$-algebra then RIF, allows us to construct
a contextual empirical family.
\begin{lemma}[Any larger $\sigma$-algebra is contextual]
    Suppose $\mathcal G$ is a $\sigma$-algebra on a joint frame such that 
    $\mathcal F_\text{ptr} \subsetneq \mathcal G$. Then there exists a empirical family
    $\left\{\mu_i\right\}_{i \in I}$ for which no consistent probability measure $\mu$
    exists on the joint frame with $\mathcal G$.
\end{lemma}
\begin{proof}
\end{proof}
Both together allow us to conclude
\begin{theorem}[The Pointer Algebra is the maximally informative non-contextual $\sigma$-algebra]
    The algebra $\mathcal F_\text{ptr}$ is maximally informative. That is, any other 
    event from the interaction frame, allows contextuality.
\end{theorem}
\begin{proof}
    Immediate from both lemmas.
\end{proof}
\section{Quantum Mechanics}
Here we endevor to trace the parallels with standard quantum mechanics. Where each
ingredient fits in the picture of information frames we have built and how are they related.
\subsection{Observables, Measurements and Operators}
\subsubsection*{Measurement Device}
We begin by defining the measurement devices. In this theory a measurement device is
given by a pure information frame $\mathscr I_{\text{mes}}$.
That is a measurement device is represented by $\left(\Omega_{\text{mes}}, 
\mathcal F_{\text{mes}}\right)$, it can be seen as what the measurement device sees about
the world, the events it is capable of recognizing.
\subsubsection*{Observables}
An observable, for a particular measurement device $i$, is a random variable 
$O_i: \Omega_i \to \mathcal O$. Where $\mathcal O$ is the outcome space, it can be 
$\mathbb R$ or other such spaces.

Each observable through the original embeddings, induces a global random variable 
on the joint context, which we will
denote with $\left(\Omega, \mathcal F\right)$. To define the global random variables we 
need the partial inverse:
\[
    \pi_i: \iota_i(\Omega_i) \to \Omega_i
\]
Then the representative of the observable in the joint frame is:
\[
    \widetilde{O}_i := O_i \circ \pi_i: \Omega \to \mathcal O
\]
The $\sigma$-algebra generated by $\widetilde{O}_i$ represents the set of events 
distinguishable by the observable $O_i$. We say observables are \textbf{compatible} if 
their algebras remain jointly Boolean. 
\subsubsection*{Observable Operators}
To see how incompatible observables do not commute, we can look at a strategy similar
to what we did we the full algebras, it also the representation that matches operators
more directly. 
Start with a event $E$ in the global space, for observables of different contexts 
$O_i$ and $O_j$ we can define:
\[
    e_i^{O_i} := \iota_i(O_i^{-1}(O_i(\pi_i(E))))\quad \text{and} 
    \quad e_j^{O_j} := \iota_j(O_j^{-1}(O_j(\pi_j(E))))
\]
If they are incompatible, we will have:
\[
    e_i^{O_i} \circ e_j^{O_j} \neq e_j^{O_j} \circ e_i^{O_i}
\]
Similarly to what we saw for local projections.
\subsubsection*{Unitary Evolution}
Basicaly it is automorphism selection.
%TODO: continue this
\subsubsection*{General Operators}
Other operators, those not associated with observables such as stochastic maps, 
or Hilbert-space operators without direct observational intrepetation appear
only as a transformation built from the basic local projections of Definition~5.2 and 
their compositions and mixtures.

In general, in the Hilbert space representation, the contextual transformations 
are represented by completely positive maps associated with the corresponding measurement.
\subsubsection*{Measurement}
A measurement of an observable $O_i$ corresponds to evaluating its lifted form 
$\widetilde{O}_i: \Omega \to \mathcal O$. However, the collapse theorem restricts the
physically admissible events to those lying in the pointer $\sigma$-algebra 
$\mathcal F_{\text{ptr}}$.

Consequently, only those values of $\widetilde{O}_i$ whose events are compatible with
$\mathcal F_{\text{ptr}}$ can occur as outcomes. In this sense, measurement reduces 
to evaluating the observable on the pointer algebra. The observable possible values are
exactly those that survive the collpase into $\mathcal F_{\text{ptr}}$.

Once a definite outcome happens after sampling. The frames carry the information 
of that outcome. Effectively, the algebras are conditioned on the outcome $A$. That is
\[
    \mathcal F \mid A := \left\{E \cap A : E \in \mathcal F\right\}
\]
That is, the perspectives of the frames are filtered to the outcome produced.
\subsection{Born Rule Martingale}
In this section we explore how the Born rule appears in this framework. We do not claim,
with the current tools, to recover the quadratic nature of the born rule or its usual 
form. That is left to a reconstruction of the Hilbert space.

\subsubsection*{Setup}
First we consider a particular context's frame $\mathscr I_i$. We define a probability
measure representing that frame $\mu_0$. Th

In the joint frame we can look at the pushfoward measure given by the original embedding.
\[\mu := \mu_0 \pi_i = \mu_0(\pi_i(E)) \quad E \in \mathcal F_\mathcal J\]
We note that this probability measure does not, nescessarly, represent all contexts of
the joint frame. In fact, in contextual cases, that is not possible. This is simply
the probability of the context $i$ transported to the global frame.

In fact, this pushfoward probability is the probability distribution given by the quantum
trace rule for the observable of that context. To see this, simply consider the observable
model we had before and note:
\[
    \mu(\widetilde{O}_i^{-1}(B)) = \mu_0(O_i^{-1}(B))
\]
In the Hilbert space, this looks like:
\[
    tr(\rho E_B) = \rho(E_b)
\]
\subsubsection*{The Collapse Filtration}
The collpase theorem, in particular for each partial $\mathcal F_{\text{ptr}} \subsetneq
\mathcal G \subseteq \mathcal F_\mathcal J$, is a sub-$\sigma$ of $\mathcal F_\mathcal J$.

So we can define the reverse filtration converging to the pointer basis.
\[
    \mathcal F_\mathcal J =: F_0 \supseteq F_1 \supseteq F_2 \supseteq ... 
    \mathcal F_\text{ptr}
\]
This filtration can be seen as the joint space being coarse grained to the pointer basis.
\subsubsection*{The Collapse Martingale}
We can now use $\mu$ as a probability measure to define, for any event $A \in 
\mathcal F_\mathcal J$ we define:
\[
    M_n := \mathbb E_{\mu}\left[ \bold{1}_A \mid \mathcal F_n\right]
\]
As seen \cite{Williams1991} we know this is a Martingale on the reverse filtration, 
and by Doob convergence theorem we have:
\[
    M_n \rightarrow \mathbb E_{\mu}\left[\bold{1}_A \mid F_\text{ptr}\right] \quad 
    \text{(a.s.)}
\]
Which means that the probability of event $A$ in the pointer filtration is exactly $\mu(A)$.
\subsection{Wigner's Friend Consistency}
We will now turn our attention to looking at how Wigner's Friend paradox looks like in this
framework.
\subsubsection*{Setup}
For the Wigner friend scenario we acutually have two interactions. First the interaction
of the friend, which we will map to the joint frame $\mathcal J_\text{friend}$. Which
represents the interaction between the system and the friend.

Once that interaction goes through the system has collapsed to the pointer frame
$\mathcal J_\text{friend}^\text{ptr}$. Then Wigner comes and interacts with that joint
frame, forming a new frame $\mathcal J_\text{Wigner}$, which again must collapse to 
$\mathcal J_\text{Wigner}^\text{ptr}$.

We use the fact that, these algebras can all be seen as filtrations of each other to show
that, Wigner cannot assign inconsistant probabilities to the events it can observe.
\subsubsection*{The Sequence of Filtrations}
When the friend interacts with the system, he generates the joint frame 
$\mathcal J_\text{friend}^\text{ptr}$. When Wigner interacts with that frame, a new
joint frame must be built. That joint frame starts by lifting the algebras through the
embeddings $\iota_\text{friend}$ and $\iota_\text{Wigner}$.

The nature of embeddings mean we can consider this all a sequence of filtrations on the
same space. Namely:
\[
    \mathcal F \supseteq \mathcal F_\text{friend}^\text{ptr} 
    \supseteq F_\text{Wigner}^\text{ptr}
\]
With these filtrations in place, we can look at the same style of probability assignments
we had in the born rule.
\subsubsection{The Probabilities}
Now let $A \in \mathcal F_\text{Wigner}^\text{ptr}$
be a event that exists in the final pointe algebra. That is, a event that all systems
involved can talk about.

We can determine the friend's probaility for event $A$ as we did for the born rule 
martingale:
\[
    M_\text{friend} := \mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{friend}^\text{ptr}\right]
\]
Now for Wigner, we have the same:
\[
    M_\text{Wigner} := \mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right]
\]
But since we have
\[
    F_\text{Wigner}^\text{ptr} \subseteq \mathcal F_\text{friend}^\text{ptr} 
    \subseteq \mathcal F
\]
The tower law for martingales gives:
\[
    \mathbb E_\mu \left[M_\text{friend} \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right] = 
    \mathbb E_\mu \left[\mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{friend}^\text{ptr}\right] \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right] = \mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right]
\]
Thus, when the friend's description is updated to the Wigner's pointer frame is 
exactly Wigner's own description.
\subsection{The Hilbert Space Realization}
We will not attempt a full Hilbert space reconstruction in this paper. But we note the
relations to previous work that fits this picture and where some structure might help
narrow some things.
\subsubsection*{The Orthomodular Lattice}
We have Boolean $\sigma$-algebras corresponding to each context $\mathcal F_i$. We have
their embeddings $\iota_i$ into the joint frame.

We can then define on the joint frame:
\[
    \mathcal L := \text{ the closure of } \bigcup_i \iota_i(\mathcal F_i)
\]
Events here have:
\begin{itemize}
    \item events complement $E\rightarrow E^c$,
    \item events meet $E \wedge F = E \cap F$,
    \item events join $E \vee F = \text{cl}_\mathcal L (E \cup F)$,
\end{itemize}
\begin{proposition}[$\mathcal L$ is a orthomodular lattice]
    The event structure $\mathcal L$, generated by all frame embeddings in the joint frame
    is an orthomodular lattice. Each frame embeds as a maximal Boolean subalgebra of 
    $\mathcal L$. Contextuality is exactly the failure of distributivity in $\mathcal  L$
    and what makes it orthomodular.
\end{proposition}
\begin{proof}
    The relation to contextuality allows us to use the standard theorems such as 
    \cite{Gleanson} to see how this algebra represents a orthomodular lattice.
\end{proof}
\subsubsection*{The Complex Field}
While we don't attempt to prove the uniqueness of the choice of the complex field in this
work we note that, accumulation of amplitudes and its removal through the RIF principle
leaves space to narrow down amplitudes that fit $\mathbb C$ over something like $\mathbb H$.
\subsubsection*{The Hilbert Space}
Under the usual regularity assumptions on $\mathcal L$, the standard representation theorems
of quantum logic apply (e.g \cite{Piron}, \cite{Soler}, \cite{Gleason}). 
Therefore there exists a Hilbert space $\mathcal H$ and a lattice
isomorphism.
\[\mathcal L \cong \mathsf{Proj}(\mathcal H)\]
\subsubsection*{The Pointer Algebra}
Each frame corresponds to a maximal commuting family of projections in $\mathcal H$. The
pointer algebra $\mathcal F_\text{ptr}$ becomes the lattice of projections associated with
a single classical basis (a maximal distributive subalgebra). 

Thus the pointer corresponds to the diagonal projections in a distinguished basis, the 
pointer basis.
\subsubsection*{States in the Hilbert Space}
Since $\mathcal L$ carries empirical probability measures representing the pushfoward
from the frames preparations as we done previously, Gleanson's theorem \cite{Gleanson}
implies that each measure corresponds uniquely to a density operator $\rho$ on $\mathcal H$.

The born rule then, as we have seen appears as the familiar trace rule:
\[
    tr(\rho E_B) = \rho(E_b)
\]
\section{Dynamics}
In this version of the framework, dynamics is not introduced as a primitive law like a 
Hamiltonian flow or differential equation. Instead, dynamics arises from the structure
of interactions between information frames.

Each interaction between contexts induces:
\begin{itemize}
    \item A creation of a joint frame,
    \item followed by collapse to its pointer algebra,
    \item and a pushfoward updated of the preparation measure.
\end{itemize}
Thus, from a fixed frame point of view, the time evolution of it's description of the world
is simply a sequence of coarse-grained $\sigma$-algebras obtained from sucessive interations,
effectively a filtration:
\[
    \mathcal F_\text{frame} =: \mathcal F_0 \supseteq 
    \mathcal F_1 \supseteq \mathcal F_2 \supseteq ... \supseteq \mathcal F_n \supseteq ...
\]
This point of view makes several dynamical properties appear naturally:
\begin{enumerate}
    \item Arrow of Time

        Because each contextual interaction corresponds to additional coarse-graining,
        the evolution of $\sigma$-algebras is monotone (information losing). This
        monotonicity defines a natural direction of time.
    \item Locality Graph

        Interactions occur only between specific frames. The pattern of which frame couples
        to which determines a graph structure, which plays the role of space locality.
    \item Maximum Speed of Influence

        In contextual scenarios, incompatibility forces coarse-graining. The maximal number
        of interaction steps before contextuality appears bounds how "fast" influence can
        propagate along the locality graph.
    \item No Signaling

        Because interactions only merge $\sigma$-algebras along edges of the locality graph,
        and collapse happens locally on the joint frame, no frame can influence another 
        without a mediated interaction.
\end{enumerate}
None of these dynamical features require any additional axioms. They follow from Axiom~1 
and the definitions of how interactions are built.
\subsection{Arrow of Time}
In this framework, time is not an external parameter. Instead we use the ordering of 
interactions between information frames to induce a canonical direction: each interaction
generates a joint frame where the initial frame algebra is embedded, collapse forces a
coarse graining of its algebra, this monotone loss of distinguishability defines a 
natural arrow of time for that frame.
\subsubsection*{Interaction-induced evolution of $\sigma$-algebras}
To begin, we first fix a information frame $\mathscr I_0$. It then proceeds to interact
with several frames $\mathscr I_{j_1}, \mathscr I_{j_2}$ and so on. 

At each step, a joint frame is first created to host the interaction, Axiom~1 and the 
collapse theorem then converge into a physically realizable joint frame with a sigma algebra
\[
    \mathcal F_{\mathcal J_n}^{\text{ptr}}
\]
That is, the pointer frame on the $n$-th joint frame. Since this is always constructed
by embedding the original $\sigma$-algebra $\mathcal F_0$, we can track its evolution
along the interactions.

We can look at the events of $\mathcal F_0$ that survive in the pointer frame 
$\mathcal F_{\mathcal J_1}^\text{ptr}$ as the $\sigma$-algebra of $\mathscr I_0$ at step
1. That is:
\[
    \mathcal F_1 := \mathcal F_{\mathcal J_1}^\text{ptr} \cap \iota_1(\mathcal F_0)
\]
This gives a natural sequence:
\[
    \mathcal F_0 \supseteq \mathcal F_1\supseteq \mathcal F_1 \supseteq ...
\]
Each step removes events that are incompatible with the new join. The future 
$\sigma$-algebras representations of $\mathcal F_0$ are strictly coarser algebras. There
is no way physical way in the framework to restore the lost distinctions.
\subsection{Locality Graph}
In this theory, \textbf{locality} is not a geometric primitive yet. It is the combinatorial
structure that records which frames have interacted and must therefore share a joint
pointer algebra.
\subsubsection*{The Locality Graph}
Let $\left\{\mathscr I_i\right\}_{i \in I}$ be a family of relevant information frames. We
define the graph:
\[
    G = (V,E)
\]
\[
    (i,j) \in E \quad \iff \quad \text{frames }\mathscr I_i \text{ and } \mathscr I_j
    \text{ have interacted.}
\]
And at every point, an edge represents there is a joint frame where the collapse has
taken place between $(i,j) \in E$.
\subsubsection*{Locality as constraint on the pointer basis}
If frames $i$ and $j$ have interacted, then their local projections $e_i$ and $e_j$ both
act on the same joint frame. Namely the pointer basis there must satisfy:
\[
    \mathcal F_\text{ptr} \subseteq \text{Fix}(e_i)\cap \text{Fix}(e_j)
\]
And if they have not interacted their projetions do not constrain the same $\sigma$-algebra,
which means:
\begin{itemize}
    \item Frames in the same subgraph in $G$ influence one another through constraints in
        the same pointer algebra
    \item Frames in different subgraphs remain completely independent. No constraints 
        propagate between them.
\end{itemize}
This reproduces the operational notion of locality, influence propagates only along paths in
the interaction graph.
\subsubsection*{Dynamics respects the locality graph}
When a new interaction occurs between frames $i$ and $j$ we:
\begin{enumerate}
    \item add an edge $(i,j)$ to $G$;
    \item build the joint frame of all contexts in the connected component containing $i$ 
        and $j$
    \item collapse using all local projections in that component.
\end{enumerate}
Therefore every subgraph of $G$ behaves as local regions, every interaction affects only 
the $\sigma$-algebra generated by its own components.

Locality therefore appears as:
\begin{itemize}
    \item graph locality where edges are interactions
    \item probabilistic locality conditional expectations factor across components of the
        sub graph
\end{itemize}
\subsubsection*{Intrepretation}
This provides a structural notion of spacetime locality:
\begin{itemize}
    \item Information frames as "positions".
    \item Interactions as "lightlike" adjacency.
    \item Paths in G are the only channels through which constraints can propagate.
\end{itemize} 
There is no geometry at this stage, geometry would be additional structure placed on top
of the locality graph.

We emphasize that "locality" and "time" in this theory are entirely structural notions.
They arise from the patterns of interactions between frames, not from any pre-assumed 
geometric spacetime. Any system that can be expressed through interacting information frames
possesses a well-defined locality graph and a induced temporal order, even when no 
traditional spacetime background is specified.
\subsection{Maximum Speed}
In this framework, influence can propagate only through interactions between frames, and
such interactions are encoded by edges in the locality graph $G$.

However contextuality imposes an additional constraint: after a sufficiently long chain
of interactions on mixed degrees of freedom, contextual incompatibility nescessarely appears.
Forcing a coarse-graining of the joint $\sigma$-algebra. This defines a \textbf{time step},
the length of the chain in that time step is always bounded by contextuality.
\subsubsection*{Contextuality forces coarse-graining}
A fundamental structural fact of contextuality (\cite{Abramsky&Brandenburger}) is that
for a sufficiently large family of information frames on shared degrees of freedom, their
combined $\sigma$-algebra on the joint frame cannot remain non-contextual.

While this is not a formal statement, as we could stay replaying interactions on 
non-contextual frames, in realistic scenarios contextuality will show up. At such step,
the pointer algebra will nescessarly coarse grain for some frame. That frame then sees
the length of the chain over the time step as the first interaction step.

Over several interactions, such chains which are always finite, have varying length. But 
any such interaction will have a finite upper bound.
\subsubsection*{Maximum speed for frame $i$}
Once we fix a frame $i$ we see its interaction path in $G$ as:
\[
    i = i_0 \rightarrow i_1 \rightarrow ... \rightarrow i_n = j
\]
In the step $i_n$ is when the first coarse graining happens. We can then define:
\[
    v_i := \sup {n: \mathcal F_n = \mathcal F_0}
\]
That is, the largest number of sequential interactions along which the $\sigma$-algebra of
$i$ remains untouched.
\subsubsection*{Intrepetation}
This pehnomenon should not be interpreted as the emergence of a specific relativistic sped
such as a "speed of light". It is a structural consequence of contextuality: in any 
sufficiently rich system of interacting information frames, repeated interactions inevitably 
produce contextual incompatibilities, which force coarse-graining and thereby prevent
influence from propagating indefinitely without degradation.

The resulting bound is a maximum interaction speed inherent to the information structure
itself. Although different contexts may have different local bounds, a common finite upper
bound always exists for any fixed system.
\subsection{No Signaling}
No signaling is an immediate structural consequence of the locality graph and Axiom~1. 
Because interactions are encoded as edges in the graph, and Axiom~1 applies only on the 
joint frames of the interacting frames, no frame can influence another without a path
of interaction connecting them.
\subsubsection*{Local Independence}
Let $i$ and $j$ represent two frames. If they have never interacted, they lie on different
subgraphs of $G$. Then no local projection $e_i$ of $i$ acts on any algebra observed by $j$.

Thus any mutual time step between then leaves $\mathcal F_j$ untouched, that is:
\[
    \mathcal F_j^{n+1} = \mathcal F_j^n
\]
When that time step operates on $i$, quite simply that is, a frame cannot alter the algebra
of a frame unless they interact.
\subsubsection*{Causal Separation}
If $i$ and $j$ lie in different subgraphs, let $e_k$ bet the local projection of a new
interaction on the subgraph of $i$. Since there is no path from $k$ to $j$ the projection
$e_k$ has no overlap with the algebras $j$ can see. Therefore, $e_k$ has no effect on 
$\mathcal F_j$.

Therefore
\begin{itemize}
    \item Effects of interactions propagate only along paths in the locality graph.
    \item Only frames lying in the same subgraph can influence each other.
\end{itemize}
This is a purely structural notion of causal separation.
\subsubsection*{Intrepretation}
No signaling in this framework is almost tautological, information cannot be transmitted 
between frames that have not interacted.
\section{Intrepetation and Comparisons}
Here we explore the theory in the context of the broader literature on measurement and
study some of its features, including the implications it has on ontology. We begin with
a informal example of the framework applied to the spin of a electron. To illustrate
how this framework maps to standard Quantum Mechanics.
\subsection{Spin Example}
Consdier a concreate quantum scenario, that of a single spin-$\frac{1}{2}$ system.

We examine two incompatible measurements:
\begin{itemize}
    \item $\mathscr I_z$: spin along the $z$-axis.
    \item $\mathscr I_x$: spin along the $x$-axis.
\end{itemize}
Each frame is represented by a two-outcome algebra:
\[
    \mathcal F_z = \left\{\emptyset,\{\uparrow_z\},\{\downarrow_z\}, \Omega_z\right\} \quad
    \mathcal F_x = \left\{\emptyset,\{\uparrow_x\},\{\downarrow_x\}, \Omega_x\right\}
\]
These are Boolean $\sigma$-algebras describen the events accessible to measurements in their
respective basis.

We begin with a free particle $\mathscr I_{\text{part}}$. This particle makes no 
distinctions about its own internal spin. So for this experiment, its algebra is considered
trivial.

The particle then interacts first with $\mathscr I_x$. This generates a joint frame where
the interaction can take place with algebra exactly:
\[
    \mathcal F_1^{\text{ptr}} = \mathcal F_x = \left\{\emptyset,\{\uparrow_x\},
    \{\downarrow_x\}, \Omega_x\right\}
\]
The observable is sampled there and obtains event $\uparrow_x$. Then the structure of the
joint frame is conditioned on this event. That is, the actual state is:
\[
    \mathcal F_1\mid \{\uparrow_x\} := \left\{E \cap \{\uparrow_x\}: E \in 
    \mathcal F_1\right\}
\]
Then, if we were to measure again on the same basis, this encodes running the same 
observable on the joint space. The only possibility in the restricted algebra is 
$\uparrow_x$.

Intuitively, the frame saw $\uparrow$ so the events, even in the measurement apparatus 
frame are conditioned on $\{\uparrow_x\}$. Now a new apparatus $\mathscr I_z$ comes and 
interacts with the system.

That leads to a new joint frame being built, and a new pointer basis, but here the 
observables are contextual so the pointer basis is given by:
\[
    \mathcal F_2^{\text{ptr}} = \left\{E\; \mid \; e_z \circ e_x (E) = e_z(E)\right\}
\]
But this pointer algebra is still conditioned on $\{\uparrow_x\}$. So effectively the state
is:
\[
    \mathcal F_2^{\text{ptr}} \mid \{\uparrow_x\}
\]
The Hilbert space representation of the spin-$x$ on the basis of $z$ show that there are
events that surive the $z$ measurement in the pointer basis. Furthermore the fact that the
algebra is conditioned on $\{\uparrow_x\}$ means we get:
\[
    \uparrow_z \quad \text{ with probability } \quad \frac{1}{2}
\]
\[
    \downarrow_z \quad \text{ with probability } \quad \frac{1}{2}
\]
Whatever outcome we get here, will again condition $\mathcal F_2^{\text{ptr}}$. If we measure
again on $z$ we will only be able to get definite outcomes.

But if we were to measure on $x$ on the joint frame conditioned on the event 
$\{\uparrow_x\}$ there would be two possible outcomes, with probability defined by the 
$z$ basis.
\subsection{The Ontology of Information Frames}
\subsection{Comparisons - Collapse Models}
\subsection{Comparisons - Intrepetations}
\section{Discussion}
\subsection{Geometry and Dynamics}
By taking the Markov view in section 5.5 we can explore this framework from the point of
view of the fisher metric. When contextuality happens, the ricci curvature of the fisher
metric blows up. That should trigger a back action on the tensor to adjust for the pointer
basis.

Known derivations of the schrodiger equation using the quantum fisher metric can be explained
and made canonical with this framework.

Furthermore, one can define a action principle of interactions. Using information geometry,
we believe that can give a new way to model physical systems.
\subsection{The Complex Field}
\subsection{Reconstruction Programs}
\subsection{Spacetime}
\section{Conclusion}

\phantomsection
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}

\bibitem{Williams1991}
D. Williams,  
\textit{Probability with Martingales},  
Cambridge University Press, 1991.

\bibitem{Pollard2002}
D. Pollard,  
\textit{A User’s Guide to Measure-Theoretic Probability},  
Cambridge University Press, 2002. 
\bibitem{Kallenberg}
O. Kallenberg,  
\textit{Foundations of Modern Probability},  
Springer, 2002.
\bibitem{Csiszar}
I. Csiszár,
\textit{Information-type measures of difference of probability distributions and indirect observation},  
Studia Sci. Math. Hungarica, 1967.

\end{thebibliography}
\end{document}

