\documentclass[11pt]{article}
\usepackage{amsmath, amsthm, amssymb, physics, geometry, mdframed, authblk}
\usepackage{xcolor}
\usepackage{microtype}
\usepackage{booktabs}
\usepackage[hidelinks]{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{mathrsfs}
\geometry{margin=1in}

\title{On Measurement: The Relativity of Information Frames}
\author[ ]{Gabriel Masarin}
\affil[ ]{\texttt{g.masarin@proton.me}}
\date{19 November, 2025}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\usepackage{setspace}
\setstretch{1.07}
\clubpenalty=10000
\widowpenalty=10000
\setlength{\belowdisplayskip}{0.8\baselineskip}
\setlength{\abovedisplayskip}{0.8\baselineskip}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newmdenv[
  backgroundcolor=gray!10,
  linecolor=gray!50,
  linewidth=1pt,
  roundcorner=6pt,
  innertopmargin=8pt,
  innerbottommargin=8pt,
]{principlebox}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheoremstyle{axiomstyle}% <name>
  {8pt}% <Space above>
  {8pt}% <Space below>
  {\itshape}% <Body font>
  {}% <Indent amount>
  {\bfseries}% <Theorem head font>
  {.}% <Punctuation after theorem head>
  {0.5em}% <Space after theorem head>
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}% <Theorem head spec>

\theoremstyle{axiomstyle}
\newtheorem{axiom}{Axiom}
\begin{document}
\maketitle

\vspace{0.5em}
\begin{abstract}

\end{abstract}

\section{Introduction}
In this paper we begin with a motivational intuition. That of a principle of relativity.
We then throught the paper endevor to make that intuition mathematically precise. First
by introducing the tools we will use, sheaf theory contextuality and markov kernels. Then
we use these tools to give a precise meaning to this relativity principle.

Finally we show that this principle generates a space that has the properties of a Hilbert
space. Using Gleanson's theorem \cite{gleanson} we retrieve the born rule. We give a natural
explanation for the pointer basis and give as a theorem Wigner friend's consistency,
natural Markoviality of physical systems and the arrow of time.

We conclude with a ontological intrepetation of this principle and suggestions for further
reasearch directions. We conclude that, if this principle is accepted as a valid restriction
for reality, the Copehangen intrepetation axioms are derived instead of postulated. Giving
a potential solution to the measurement problem.

We also compare it to other explanations such as GRW and Penrose collapse. Also relates
to its direct cousin, Relation Quantum Mechanics. This is not a intrepretation but a new
framework.

Acceptance of this principle depends upon accepting the Relativity of information frames
as physically fundamental. Further work is needed to see its consequences, in principle
it does not disagree with quantum mechanics and provides a clean resolution to some of
its puzzling features. No experiment to derive prove its truth is known to the authors of
this paper at the current formulation.

\section{Motivation - The Relativity of Information Frames}

Consider two physical observers, Alice and Bob, each equipped with a clock and a ruler.
To infer a particle’s momentum, they make two position measurements and record 
the elapsed time.

However,
\begin{itemize}
    \item If they agree on the spatial separation, they must disagree on the elapsed time;
    \item If they agree on the elapsed time, the measured spatial separation must differ.
\end{itemize}

Their interactions with the world differ — and so does what each can resolve as an event.

What Alice calls “particle at position $x$ at time $t$” is determined by her 
interaction channels and detection thresholds.

Thus there is no global, frame-independent $\sigma$-algebra of events.  
Every physical system carries its own information frame: a $\sigma$-algebra 
of distinguishable outcomes accessible through its interactions.

Einstein taught that coordinate descriptions are relative while causal order is invariant.  
We extend this principle.

\begin{principlebox}
\begin{center}
\textbf{Relativity of Information Frames (RIF)}

Nature does not privilege one information frame over another. What is physical is what
all information frames can agree upon.
\end{center}

\end{principlebox}

Measurement is not the revelation of a pre-existing global state; it is the joint refinement
(and, when necessary, coarse-graining) of information frames when systems interact.  
From this symmetry, quantum state update, pointer bases, and even causal 
geometry follow as consequences.

\section{Background}
\subsection{Measure Theory}
The complete introduction to the richness of measure theory probability theory 
is not in the scope of this work, we refer to \cite{Williams1991} for that, 
we will at least the concept of probability space. We hope the work is understandable with
only this crude introduction but familiarity with the subject is advised.

\subsubsection*{Probability Spaces}
In measure theoretical probability, a probability space consists of a triplet 
$(\Omega, \mathcal F, \mu$. Each piece represents a core element of a probality model.
\subsubsection*{The Sample Space $\Omega$}
The sample space $\Omega$ represents all events that can happen. It is often not defined
to be something in particular. Simply a space where we can draw samples $\omega \in \Omega$
from.

It can be seen as particular realizations of an experiment, or trials of a coin toss or
observations of a particular population model.
\subsubsection*{The $\sigma$-algebra $\mathcal F$}
A $\sigma$-algebra represents the set of events the model view as possible. It can be seen
as what can happen in the probability model. Events are are sets composed of samples 
$\omega \in \Omega$.

The events in a probability space must obey certain rules. The rules, 
%TODO: CONTINUE THIS SESSION
\subsubsection*{The Probability Measure $\mu$}
Throughout this paper, we will often not be using specific probability measures, 
working only with the sample space and the $\sigma$-algebras.
\subsubsection*{Measurable Functions}
\subsubsection*{Pushfoward Measure}
\subsubsection*{Markov Kernels}
We will also need the definition of \textbf{Markov Kernels}, which give us to talk about 
how different probability spaces interact.
\begin{definition}[Markov Kernels]
    Let $(\Omega_1, \mathcal F_1)$ and $(\Omega_2, \mathcal F_2)$ be two measurable 
    spaces. A \textbf{Markov Kernel} is a function:
    \[
        K: \Omega_1 \cross \mathcal F_2 \to [0,1]
    \]
    \noindent
    Where we have:
    \begin{itemize}
        \item For every fixed $\omega \in \Omega_1$ 
            \[
                K(\omega,\cdot) \text{ is a probability measure in } \mathcal F_2
            \]
        \item For every fixed $A \in \mathcal F_2$
            \[
                K(\cdot, A) \text{ is a measurable function } \Omega_1 \to
                \left([0,1],\mathcal B\left([0,1]\right)\right)
            \]
    \end{itemize}
    \noindent
    The idea is that Markov Kernels define probability measures on the target space that
    respect the structure of the source space. It is often written $K: \Omega_1 \to 
    \mathcal P(\Omega_2)$ to say, a Kernel that defines probabilities on $\Omega_2$ from
    $\Omega_1$.
\end{definition}
Markov Kernels allow us to define probability measures on the target space from measures
on the source.
\begin{definition}[Markov Pushfoward Measure]
    Given the measurable spaces and Kernel on the Definition 3~4. Let $\mu$ be a probability 
    measure on $\Omega_1$. The \textbf{pushfoward measure} given by the Kernel
    \[
        (\mu K) (A) := \int_{\Omega_1} K(\omega, A) \,\mu (dx), \qquad A \in \mathcal F_2
    \]
    \noindent
    And it is a probability measure on $\mathcal F_2$.
\end{definition}

And finally, we also need to look at the definition of a 
\textbf{effective $\sigma$-algebra} of a Markov Kernel.
\begin{definition}[Effective $\sigma$-algebra of K]
    For a Kernel $K: \left(\Omega_1,\mathcal F_1\right) \to
    \left(\Omega_2,\mathcal F_2\right)$. The effective sigma algebra of 
    $K$ is given by:
    \[
        \mathcal F_K := \sigma\left\{\omega \to K(\omega,A) 
        \mid A \in \mathcal F\right\}
    \]
    \noindent
    That is, the algebra of all random variables that $K$ generates. It can also be seen
    as the algebra of events of $\Omega_1$ that remain distinguishable after passing 
    through $K$.
\end{definition}
\subsubsection*{Composition of Markov Kernels}
Markov Kernels compose, in particular if $K_1: \Omega_1 \to \mathcal P(\Omega_2)$ and
$K_2: \Omega_2 \to \mathcal P(\Omega_3)$ are Markov Kernels. Then their composite is
given for $A \in \mathcal F_3$:
\[
    \left(K_2 \circ K_1\right)(x,A) := \int_{\Omega_2} K_2(y,A) d K_1(x,\cdot)
\]
And naturally defines probability measures on $\Omega_3$.
\subsubsection*{Deterministic Markov Kernels}
These are a special class of Markov Kernels that can act as transport structure from one 
probability space to another.
\begin{definition}[Deterministic Markov Kernels]
    Let $(\Omega_1, \mathcal F_1)$ and $(\Omega_2, \mathcal F_2)$ be two measurable 
    spaces. A \textbf{Deterministic Markov Kernel} is induced by a measurable function
    $f: \Omega_1 \to \Omega_2$:
    \[
        K_f: \Omega_1 \cross \mathcal F_2 \to [0,1]
    \]
    \noindent
    That is given for $\omega_1 \in \Omega_1$ and $F_2 \in \mathcal F_2$
    \[
        K_f(\omega_1,F_2) := \bold{1}_{f(\omega_1) \in F_2}
    \]

\end{definition}
The function $f$ can be seen as the transport from one probability space into another. The
Kernel then, allows us to pushfoward probability measures from it.
\subsubsection*{Embeddings}
As we have seen, we can use a measurable function $f: \Omega_1 \to \Omega_2$ to define
a Markov Kernel. The Markov Kernel then allows us to transport probabilities to the new
space.

There are a few special measurable functions we will be interested in. The first defines
a full \textbf{isomorphism} of spaces:
\begin{definition}[Measurable Isomorphism]
    A measurable function $T: \Omega_1 \to \Omega_2$ that is \textbf{bijective} and whose
    inverse $T^{-1}: \Omega_2 \to \Omega_1$ is also measurable defines a \textbf{isomorphism}
    of probability spaces:
    \[
        \left(\Omega_1, \mathcal F_1\right) \cong \bigl(\Omega_2, \mathcal F_2\bigr)
    \]
\end{definition}
Naturally such bijections form a group:
\begin{definition}[Measurable Space Automorphisms]
\[
    \text{Aut}_{\Omega,\mathcal F} := \left\{T: \Omega \to \Omega 
    \text{ is bijective, } T\text{ and }T^{-1}\text{ are measurable }\right\}
\]
\end{definition}
These maps preserve the full structure of the measurable space, for our work we will need
a class that still preserves structure but can embed the measurable space into a larger
one.
\begin{definition}[Measurable Embedding]
    A measurable embedding $\iota: \Omega_1 \to \Omega_2$ is a \textbf{injective} measurable
    function with a measurable inverse. It can also be seen as a local homomorphism.
\end{definition}
These embeddings preserve the $\sigma$-algebra of the source space entirely in the target
space.
\subsection{Contextuality}
The first important concept the theory relies upon is that of contextuality. All our
definitions here are translated from the \cite{Abramsky&Brandenburger} contextuality
in sheaf-theory. They have been adapted to a measure theory framework.
\subsubsection*{Labels and Contexts}
First we look at the definition of a measurement label. A measurement label intuitively
represents what one can tell apart, that is what questions a system can ask. It can be
seen as the fundamental degrees of freedom of a given model. 
\subsubsection*{Measurement Labels}
\begin{definition}[Measurement labels]
    A measurement label is an abstract symbol $m$ that identifies a physical distinction
    we may attempt to extract from the system. Together with its outcome 
    space $(\Omega_m, \mathcal F_m)$. That is:
    \[
        m \to (\Omega_m, \mathcal F_m)
    \]
    The set of all measurement labels the model considers primitive is called $\mathcal M$.
\end{definition}

Then naturally, our global space, where all measurament labels exist is then:
\begin{definition}[Global Space]
    The global space, the space of all degrees of freedom and all their distinctions is 
    \[
        \left(\Omega_{\mathcal M}, \mathcal F_{\mathcal M}\right) = 
        \left(\prod_{m \in \mathcal M} \Omega_m \;, \bigotimes_{m \in \mathcal M} 
        \mathcal F_m \right)
    \]
    \noindent
    Where $\mathcal F_1 \otimes \mathcal F_2 = 
    \sigma\left(\left\{F_1 \times F_2: F_1 \in \mathcal F_1, F_2 \in 
    \mathcal F_2\right\}\right)$. We note that, we do not define a particular probability measure on this space, that
    is because what we are interested in at the moment is the structure of the space,
    not a specfic measure on it.
\end{definition}

\subsubsection*{Contexts}
Next we talk about contexts. Contexts are given by the subset of labels or degrees of
freedom a given observer cares about something he is interacting with. It can be seen
as the fundamental set of questions he can ask about the part of the model he interacts 
with.

\begin{definition}[Context]
    A context $C \subseteq \mathcal M$ is a finite collection of 
    measurement labels that are jointly meaningful. 
    To each context we associate a measurable space:
    \[
        (\Omega_{C}, \mathcal F_{C}) := \left(\prod_{m \in C}
        \Omega_m \;, \bigotimes_{m \in C} \mathcal F_m \right)
    \]
\end{definition}

Within a context we also define the projections:
\begin{definition}[Canonical Context Projections]
    The projections for a context $C$ are defined as \textbf{measurable functions} from a
    context to one of its label spaces.
\[
    \pi_{C \to \{m\}}: \Omega_C \to \Omega_m
\]
With:
\[
    \pi_{C \to \{m\}}\left(\omega\right) = \omega_m \quad \forall \omega \in C
\]
\noindent
That is, the projections map to the context corresponding to the label $m$ within
the context $C$. The extension to a subcontext $D \subseteq C$ is naturally
$\pi_{C\to D}$.
\end{definition}
Intuitively projection can be seen as the \textbf{perspective} $C$ has on $m$. 
For context projection we will also need its inverse definition.
\begin{definition}[Cylinder Embedding]
    For every outcome $\omega_1 \in \Omega_m$ we embed it in the context space 
    $(\Omega_C,\mathcal F_C)$. This gives the definition:
    \[
        \pi_{C\to\{m\}}^{-1}(A) := \left\{\omega \in \Omega_C:\; x_m \in A\right\}
    \]
    \noindent
    Since $\pi$ is a measurable function by definition $\pi_{C\to\{m\}}^{-1}(A) \in 
    \mathcal F_C$.
\end{definition}

We importantly note that, a context require $\pi$. They tell the context where its events
come from. In principle, a context does not hold \textbf{information that comes from nowhere.}

\subsubsection*{Empirical Model}
We will now introduce the first concept that requires the use of specific probability 
measures that is the definition of an \textbf{empirical model}. 

Intuitively can be seen as a particular realization of the model, or a 
particular realization of a \textbf{perspective} on the underlying world. 
We can also think of it as a particular family of \textbf{coodinates} in the probability 
spaces of the contexts.
\begin{definition}[Empirical model]
    An \textbf{empirical model} is a family $\left\{e_C \right\}_{ C \in \mathcal M}$ 
    of probability measures on $\left(\Omega_C, \mathcal F_C\right)$. 
    For all $C,C' \in \mathcal M$ and all $D \in C \cap C'$ we have:
    \[
        \left(\pi_{C \to D}\right)_* e_C \; = \; \left(\pi_{C' \to D}\right)_* e_{C'}
    \]
    This condition means that on overlaps, the probability measures must agree. They
    come from the same underlying labels.
\end{definition}

\subsubsection*{Contextuality}
The empirical families allows us to define what will be the driving feature of our 
framework. It is the defintion of \textbf{Contextuality}. When \textbf{perspectives} 
only completly exist on the context they came from.

\begin{definition}[Contextuality]
    The family $\left\{e_{E} \right\}_{ E \in \mathcal M}$ is called contextual 
    in $\mathcal M$ if no probability measure $\mu$ on the global space $\mathcal M$ 
    exists satisfying:
    \[
        \left(\pi_{C \to E}\right)_* \mu \; = e_{E} \quad \forall E \subset \mathcal M
    \]
    \noindent
    They are called non-contextual, if such probability measure exists.
\end{definition}

Intuitively, it means that in that shared space, the questions still make perfect sense
together if they are non-contextual. We know exactly where they came from.

If they are contextual then there is no way to pick a coordinate, or probability measure
on the global space that agrees with all probabilities the contexts of that space found.

The core feature we will need here is that, there exists experiments or real situations
where the global space is contextual this fact can be seen in depth in 
\cite{Abramsky&Brandenburger}. This particular definition, is of probabilistic 
contextuality as defined on \cite{Abramsky&Brandenburger}.
\section{Structural Contextuality}
To get a better understanding on RIF we need to look at other formulations of 
contextuality. We want to understand contextuality without particular probability 
distributions.


For this, we adapt the sheaf like condition, than just the failure of probabilities to
have the correct marginals, this in particular matches the \textbf{strong contextuality} 
defined in \cite{Abramsky&Brandenburger}. First we define a \textbf{Information Frame}.

\begin{definition}[Information Frame]
    A information frame is a probability space over a context $C \subseteq \mathcal M$ 
    with a particular event algebra 
    $\mathcal F \subseteq \bigotimes_{m \in C} \mathcal F_m$ corresponding to the set
    of distinctions that frame can see about the labels $m$.
    \[
        \mathscr I_{C, \mathcal F} := \left(\prod_{m \in C} \Omega_m, \mathcal F\right)
    \]
    \noindent
    A information frame could be seen as a perspective on the world. A view of what it
    can in principle see about a system. A probability measure there represents a 
    particular state of the world. For notation convinience we will use 
    $\mathscr I_1 = \mathscr I_{C1, \mathcal F_1}$
\end{definition}

In general, Information Frames are defined on the support of some probability measure,
meaning we get rid of events that a context does not see as possible. \begin{definition}[Structural Contextuality]
    Given a family of contexts $\mathcal C$ of $\mathcal M$ and corresponding 
    information frames $\mathscr I_{C, \mathcal F_C}$ and a global space 
    $\left(\Omega, \mathcal F\right)$. 

    The family is said to be \textbf{structuraly non-contextual} if there is a family of 
    corresponding \textbf{embeddings} and some sub-$\sigma$-algebra 
    $\mathcal G \subseteq \mathcal F$ such that:
    \[
        \iota_{C \in \mathcal C}: \mathscr I_{C, \mathcal F_C} \to 
        \left(\Omega, \mathcal G\right)
    \]
    Such that for every pair $C,C'$ and every event 
    $E \in \mathcal F_C \cap \mathcal F_{C'}$, that is events on shared labels, we have:
    \[
        \iota_C(E) = \iota_{C'}(E)
    \]
    \noindent
    If no such embedding exists then the family is called \textbf{structuraly contextual}.
\end{definition}

The existence of \textbf{strong contextuality} as seem in \cite{Abramsky&Brandenburger} 
guarantees structural contextuality also exists, in particular the results in 
\cite{Kochen-Specker} show that, if we try to keep the full $\sigma$-algebra event structure, 
structural contextuality will eventually happen. This shows contextuality is 
essentially inevitable in sufficiently complex logics.
\section{The Relativity Of Information Frames}
\subsection{Interaction}
Now we work on making precise the meaning of the \textbf{Relativity of Information Frames}, 
RIF, for short. To do so, the central objects of study will be \textbf{Information Frames} as
in defintion 4~.1. Information frames are the only ontic objects in this theory, 
everything works on their interactions.

We now turn our attetion to making the definition of interaction precise. 
The first step is to define the \textbf{Joint Frame}. A information frame where 
the interaction takes place. Before this we will note that when we write:
\[
    \iota(\mathcal F_C) := \mathcal G 
\]
That is, there is some sub-$\sigma$-algebra $\mathcal G$ on the global space where that
embedding exits. We also note that there can be many such embeddings. 
These differences are not of particular interest to us, they are related 
by the automorphism symmetry defined in Definition~3.7, so we can treat them as equivalent.
\begin{definition}[Joint Frame]
    Given a family of information frames $\left\{\mathscr I_i\right\}_{i \in I}$ we 
    can construct their joint frame as:
    \[
        \mathcal J_{I} :=\left( \Omega_{\mathcal J_I},\; \mathcal F_{\mathcal J_I}\right) 
        := \left(\prod_{m \in \{\bigcup_{i \in I}C_i \subseteq \mathcal M\}}
            \Omega_{m},\; 
        \bigotimes_{i \in I}\iota_i\left(\mathcal F_i\right)\right)
    \]
    \noindent
    The space that hold all distinctions of all information frames.
\end{definition}
Such joint frame always exists, but it might be contextual. Structural contextuality tells
us directly when it is even possible to make a non-contextual joint frame.

One important thing to note however, is that once we generate such a joint space, the 
embeddings are no longer nescessarly embeddings. That is because in contextual cases,
the event in the intersection $E$ must choose one of the embeddings. This is critical
for our relativity principle.
\subsection{The Structure of the contexts}
To make our realitivity principle precise we need a way to compare the structure of contexts 
in the joint frame.The problem is once we fix a joint frame $\mathcal J_I$ through some 
family of embeddings $\iota_{i \in I}$ we still can't properly compare the contexts as
they do not live in the global space.

A way to do this is to consider the following map
\begin{definition}[Local Projections]
Given a family of embeddings $\iota_i$ that generated a particular frame $\mathcal J_I$.
The local projections $e_i$ are
\[
    e_i := e_{C_i} := \left( \iota_i\circ \pi_{\mathcal J_I \to C_i}\right): 
    \Omega_{\mathcal J_I} \to \Omega_{\mathcal J_I}
\]
\end{definition}
These $e_{i}$ represent the full event structure of the frame $\mathscr I_i$ in the joint
frame.
\subsection{The Symmetry Of Information}
\subsubsection*{Privilege}
We are finally ready to introduce the concept of \textbf{The Relativity of Information Frames}.
We begin with the definition of \textbf{Privilege} in a \textbf{Joint Frame}.
\begin{definition}[Privilege]
    We say a joint frame $\mathcal J_{C_1 \cup C_2}$ privileges $C_1$ over $C_2$ if for
    some shared event $E \in C_1 \cap C_2$ if, for its local projections $e_1,e_2$ we have:
    \[
        e_1(E) = e_1(e_2(E)) \quad \text{ and } \quad e_2(E) \neq e_2(e_1(E))
    \]
\end{definition}
The idea is that one context is favored over another if its perspective is closer to
that of the joint frame than another context. It can be thought of as preserving the
its structure more than that of another frame.

Intuitively, as the joint frame is built, if there is contextuality the joint frame
had to pick one $\iota$ over another for each event they disagreed upon. This manifests as
favoring.

Another way to see this is that, the $\iota$ of a privileged frame, is no longer a true
embedding on the joint frame with its full sigma algebra, it now forgets some distinctions.

In particular, its worth noting that the local projections do not commute in the 
contextual case:
\[
    e_1 \circ e_2(E) \neq e_2 \circ e_1(E)
\]
\subsubsection*{The Relativity of Information Frames}
We can now state the relativity of information frames precisely.
\begin{axiom}[The Relativity Of Information Frames]
    After interaction, a physically admissible frame $J_{\text{phys}}$ must not privilege
    any interacting information frame over another on any event.
\end{axiom}

More explicitly for any pair of frames $i,j$ of the joint frame and any shared event $E$
we have:
\[
    e_i(E) = e_i(e_j(E))\quad \text{ and }\quad e_j(E) = e_j(e_i(E))
\]
Equivalently, the event is in the intersection of fixed points:
\[
    E \in \text{Fix}(e_i)\cap \text{Fix}(e_j)
\]
The above condition shows that:
\[
    E \in \text{Fix}(e_i)\cap \text{Fix}(e_j) \quad \forall E \in \mathcal F_{\text{phys}}
    \quad \forall i,j
\]
We define a important object using the definition above, with $\mathcal F_I$ being the $\sigma$-algebra of the full joint frame: 
\begin{definition}[Pointer algebra]
The pointer algebra of a joint frame is given by:
\[
    \mathcal F_{\text{ptr}} := \bigcap_i \text{Fix}(e_i) = \left\{E\in 
    \mathcal F_I :\; e_i(E) = E \;\forall i\right\}
\]
\end{definition}

It is clear from the definition that:
\[
    \mathcal F_{\text{phys}} \subseteq \mathcal F_{\text{ptr}}
\]
In fact, since its obviously true that for all $E \in \mathcal F_{\text{ptr}}$
\[
    e_i(E) = e_i(e_j(E))\quad \text{ and }\quad e_j(E) = e_j(e_i(E))
\]
This intersection is the largest algebra that is physically admissible for the interaction.
\subsection{Symmetry Breaking: Collapse}
Now our study in contextuality already revealed that, the naive embedding joint frame,
that attempts to preserve all distinctions in all information frames, may yield a contextual
joint frame.

\begin{theorem}[Maximality of the pointer algebra]
    The pointer algera $\mathcal F_{\text{ptr}}$ is the largest $\sigma$-algebra that
    is physically admissible under Axiom~1.
\end{theorem}
\begin{proof}
Such joint frame cannot obey Axiom~1. Because structural contextuality shows that for any
joint frame $\mathcal J_I$ that is built from a contextual family there is some event 
$E \in \mathcal F_I$ and some pair $i,j$ for which 
\[
    e_i(E) \neq e_j(E)
\]
Therefore for at least some particular $e_i$ we must have:
\[
    \mathcal F_{\text{ptr}} \subseteq \text{Fix}(e_i)
\]
And for any $\mathcal F_{\text{ptr}}\subsetneq \mathcal G \subseteq \mathcal F_I$
we must have:
\[
    E \in \mathcal G \setminus \mathcal F_{\text{ptr}} \quad \exists k \in I \rightarrow 
    e_k(e_k(E)) \neq e_k(E) 
\]
But by construction of the joint frame, the event $e_k(E)$ must have come from some 
context. So we must have $\iota_j(E) = e_k(E)$. And this means:
\[
 e_j(E) = e_j(e_k(E)) \quad \text{ and } \quad  e_k(e_j(E)) = e_k(e_k(E)) \neq e_k(E)
\]
\end{proof}
And finally we have:
\begin{theorem}[Collapse Theorem]
    Let $\mathcal F_I$ be the contextual joint $\sigma$-algebra of the joint frame generated
    by the interaction of the contextual families $\mathcal F_I$. Let $\mathcal F_{text{ptr}}$
    be its pointer algebra.

    Then under Axiom~1 we have $\mathcal F_{\text{phys}} = \mathcal F_{\text{ptr}}$.
\end{theorem}
\begin{proof}
    For every event $E \not\in \mathcal F_{\text{ptr}}$ by Theorem~5.5 we know it exhibits 
    privilege for some pair of contexts. Therefore such events are physically forbidden
    by RIF. Every event in $\mathcal F_{\text{ptr}}$ is physically admissible. So we have:
    \[
\mathcal F_{\text{phys}} = \mathcal F_{\text{ptr}}
    \]
\end{proof}
While we do not have a dynamical picture of collapse in this work, one may picture collapse
as the effect of repeatedly applying all contextual projections. Each projection shaves off
parts of an event it cannot stabilize, only the events that survive all projections belong
to the pointer algebra.

So what survives is:
\[
    E \cap \bigcap_{i \in I} \text{Fix}(e_i)
\]
We end with the definition of the joint pointer frame.
\begin{definition}[Joint Pointer Frame]
    \[
        \mathcal J_I^{\text{ptr}} := \left(\Omega_I, \mathcal F_{\text{ptr}}\right)
    \]
\end{definition}
\subsection{Relation to Contextuality}
What we aim to do here is to show that $\mathcal F_{\text{ptr}}$ is non-contextual. While
every larger sub-sigma algebra is contextual.

But we note that, the structural definition we used before is not possible here. It requires
spaces that allow for full embeddings, which we know does not fit the pointer frame. We
provide very rough proof sketches as not to crowd the paper, but it should be enough to
see the correlation.

So we turn our attention to probabilistic contextuality. We have the following theorem:
\begin{theorem}[The Joint Pointer Frame is noncontextual]
    Let $\left\{p_i\right\}_{i \in I}$ be a empirical family of probabilties on the
    contexts. There exists a probability measure $\mu$ in the pointer frame generated
    by the information frames corresponding to that empirical family with:
    \[
        (\pi_{J\to C_i})_* \mu = p_i
    \]
\end{theorem}
\begin{proof}[Proof sketch]
    First pick the information frames with the support of each $p_i$ for its sigma algebra.
    Then construct the joint frame with embeddings. Because the event structure is picked
    only to agree with all embeddings we can restrict the embedding to common events.

    Then the probabilties will pass along to those events.
\end{proof}

For larger families the pointer frames, if a empirical famility is contextual it remains
contextual in all algebras larger than the pointer.
\begin{theorem}[Algebras larger than the pointer are contextual]
    With the same setup as the previous theorem a algebra $\mathcal F_{\text{ptr}} 
    \subsetneq \mathcal G$ there is no probability measure that has the correct partials.
\end{theorem}
\begin{proof}[Proof sketch]
    Here, since in $\mathcal G$ we still have privilege we know there are two frame's
    contexts $C_j$ and $C_k$ and shared event $E$ such that:
    \[
        e_j(E) \neq e_j(e_k(E)) \quad \text{while}\quad e_k(E) = e_k(e_j(E))
    \]
    And since there is consistency of empirical families on shared events no statistics
    on the joint frame will be able to reproduce how the statistics of this event $E$
    behave for both contexts.
\end{proof}

\subsection{The Markov View}
A important thing to note is that, once a joint frame has been built, and it has picked
a algebra. The initial embeddings are no longer nescessarely embeddings in that frame.

In fact, for the ones that are not privileged the kernel generated by the original embedding
is no longer injective. It is a strict coarse graining. This will allow us to give precise
numerics and dynamics by implementing information geometry once we are free to assume
states (particular probability distributions). But this is not in the scope of this paper.
\section{Quantum Mechanics}
Here we endevor to trace the parallels with standard quantum mechanics. Where each
ingredient fits in the picture of information frames we have built and how are they related.
\subsection{Observables, Measurements and Operators}
\subsubsection*{Measurement Device}
We begin by defining the measurement devices. In this theory a measurement device is
given by a pure information frame $\mathscr I_{\text{mes}}$.
That is a measurement device is represented by $\left(\Omega_{\text{mes}}, 
\mathcal F_{\text{mes}}\right)$, it can be seen as what the measurement device sees about
the world, the events it is capable of recognizing.
\subsubsection*{Observables}
An observable, for a particular measurement device $i$, is a random variable 
$O_i: \Omega_i \to \mathcal O$. Where $\mathcal O$ is the outcome space, it can be 
$\mathbb R$ or other such spaces.

Each observable through the original embeddings, induces a global random variable 
on the joint context, which we will
denote with $\left(\Omega, \mathcal F\right)$. To define the global random variables we 
need the partial inverse:
\[
    \pi_i: \iota_i(\Omega_i) \to \Omega_i
\]
Then the representative of the observable in the joint frame is:
\[
    \widetilde{O}_i := O_i \circ \pi_i: \Omega \to \mathcal O
\]
The $\sigma$-algebra generated by $\widetilde{O}_i$ represents the set of events 
distinguishable by the observable $O_i$. We say observables are \textbf{compatible} if 
their algebras remain jointly Boolean. 
\subsubsection*{Observable Operators}
To see how incompatible observables do not commute, we can look at a strategy similar
to what we did we the full algebras, it also the representation that matches operators
more directly. 
Start with a event $E$ in the global space, for observables of different contexts 
$O_i$ and $O_j$ we can define:
\[
    e_i^{O_i} := \iota_i(O_i^{-1}(O_i(\pi_i(E))))\quad \text{and} 
    \quad e_j^{O_j} := \iota_j(O_j^{-1}(O_j(\pi_j(E))))
\]
If they are incompatible, we will have:
\[
    e_i^{O_i} \circ e_j^{O_j} \neq e_j^{O_j} \circ e_i^{O_i}
\]
Similarly to what we saw for local projections.
\subsubsection*{General Operators}
Other operators, those not associated with observables such as time evolution, 
stochastic maps, or Hilbert-space operators without direct observational intrepetation appear
only as a transformation built from the basic local projections of Definition~5.2 and 
their compositions and mixtures.

In general, in the Hilbert space representation, the contextual transformations 
are represented by completely positive maps associated with the corresponding measurement.
\subsubsection*{Measurement}
A measurement of an observable $O_i$ corresponds to evaluating its lifted form 
$\widetilde{O}_i: \Omega \to \mathcal O$. However, the collapse theorem restricts the
physically admissible events to those lying in the pointer $\sigma$-algebra 
$\mathcal F_{\text{ptr}}$.

Consequently, only those values of $\widetilde{O}_i$ whose events are compatible with
$\mathcal F_{\text{ptr}}$ can occur as outcomes. In this sense, measurement reduces 
to evaluating the observable on the pointer algebra. The observable possible values are
exactly those that survive the collpase into $\mathcal F_{\text{ptr}}$.

Once a definite outcome happens after sampling. The frames carry the information of that
outcome. Effectively, the algebras are conditioned on the outcome $A$. That is
\[
    \mathcal F \mid A := \left\{E \cap A : E \in \mathcal F\right\}
\]
That is, the perspectives of the frames are filtered to the outcome produced.
\subsection{Born Rule Martingale}
In this section we explore how the Born rule appears in this framework. We do not claim,
with the current tools, to recover the quadratic nature of the born rule or its usual 
form. That is left to a reconstruction of the Hilbert space.

\subsubsection*{Setup}
First we consider a particular context's frame $\mathscr I_i$. We define a probability
measure representing that frame $\mu_0$. Th

In the joint frame we can look at the pushfoward measure given by the original embedding.
\[\mu := \mu_0 \pi_i = \mu_0(\pi_i(E)) \quad E \in \mathcal F_\mathcal J\]
We note that this probability measure does not, nescessarly, represent all contexts of
the joint frame. In fact, in contextual cases, that is not possible. This is simply
the probability of the context $i$ transported to the global frame.

In fact, this pushfoward probability is the probability distribution given by the quantum
trace rule for the observable of that context. To see this, simply consider the observable
model we had before and note:
\[
    \mu(\widetilde{O}_i^{-1}(B)) = \mu_0(O_i^{-1}(B))
\]
In the Hilbert space, this looks like:
\[
    tr(\rho E_B) = \rho(E_b)
\]
\subsubsection*{The Collapse Filtration}
The collpase theorem, in particular for each partial $\mathcal F_{\text{ptr}} \subsetneq
\mathcal G \subseteq \mathcal F_\mathcal J$, is a sub-$\sigma$ of $\mathcal F_\mathcal J$.

So we can define the reverse filtration converging to the pointer basis.
\[
    \mathcal F_\mathcal J =: F_0 \supseteq F_1 \supseteq F_2 \supseteq ... 
    \mathcal F_\text{ptr}
\]
This filtration can be seen as the joint space being coarse grained to the pointer basis.
\subsubsection*{The Collapse Martingale}
We can now use $\mu$ as a probability measure to define, for any event $A \in 
\mathcal F_\mathcal J$ we define:
\[
    M_n := \mathbb E_{\mu}\left[ \bold{1}_A \mid \mathcal F_n\right]
\]
As seen \cite{Williams1991} we know this is a Martingale on the reverse filtration, 
and by Doob convergence theorem we have:
\[
    M_n \rightarrow \mathbb E_{\mu}\left[\bold{1}_A \mid F_\text{ptr}\right] \quad 
    \text{(a.s.)}
\]
Which means that the probability of event $A$ in the pointer filtration is exactly $\mu(A)$.
\subsection{Wigner's Friend Consistency}
We will now turn our attention to looking at how Wigner's Friend paradox looks like in this
framework.
\subsubsection*{Setup}
For the Wigner friend scenario we acutually have two interactions. First the interaction
of the friend, which we will map to the joint frame $\mathcal J_\text{friend}$. Which
represents the interaction between the system and the friend.

Once that interaction goes through the system has collapsed to the pointer frame
$\mathcal J_\text{friend}^\text{ptr}$. Then Wigner comes and interacts with that joint
frame, forming a new frame $\mathcal J_\text{Wigner}$, which again must collapse to 
$\mathcal J_\text{Wigner}^\text{ptr}$.

We use the fact that, these algebras can all be seen as filtrations of each other to show
that, Wigner cannot assign inconsistant probabilities to the events it can observe.
\subsubsection*{The Sequence of Filtrations}
When the friend interacts with the system, he generates the joint frame 
$\mathcal J_\text{friend}^\text{ptr}$. When Wigner interacts with that frame, a new
joint frame must be built. That joint frame starts by lifting the algebras through the
embeddings $\iota_\text{friend}$ and $\iota_\text{Wigner}$.

The nature of embeddings mean we can consider this all a sequence of filtrations on the
same space. Namely:
\[
    \mathcal F \supseteq \mathcal F_\text{friend}^\text{ptr} 
    \supseteq F_\text{Wigner}^\text{ptr}
\]
With these filtrations in place, we can look at the same style of probability assignments
we had in the born rule.
\subsubsection{The Probabilities}
Now let $A \in \mathcal F_\text{Wigner}^\text{ptr}$
be a event that exists in the final pointe algebra. That is, a event that all systems
involved can talk about.

We can determine the friend's probaility for event $A$ as we did for the born rule 
martingale:
\[
    M_\text{friend} := \mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{friend}^\text{ptr}\right]
\]
Now for Wigner, we have the same:
\[
    M_\text{Wigner} := \mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right]
\]
But since we have
\[
    F_\text{Wigner}^\text{ptr} \subseteq \mathcal F_\text{friend}^\text{ptr} 
    \subseteq \mathcal F
\]
The tower law for martingales gives:
\[
    \mathbb E_\mu \left[M_\text{friend} \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right] = 
    \mathbb E_\mu \left[\mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{friend}^\text{ptr}\right] \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right] = \mathbb E_\mu \left[\bold{1}_A \mid 
    \mathcal F_\text{Wigner}^\text{ptr}\right]
\]
Thus, when the friend's description is updated to the Wigner's pointer frame is 
exactly Wigner's own description.
\subsection{The Hilbert Space Realization}
We will not attempt a full Hilbert space reconstruction in this paper. But we note the
relations to previous work that fits this picture and where some structure might help
narrow some things.
\subsubsection*{The Orthomodular Lattice}
We have Boolean $\sigma$-algebras corresponding to each context $\mathcal F_i$. We have
their embeddings $\iota_i$ into the joint frame.

We can then define on the joint frame:
\[
    \mathcal L := \text{ the closure of } \bigcup_i \iota_i(\mathcal F_i)
\]
Events here have:
\begin{itemize}
    \item events complement $E\rightarrow E^c$,
    \item events meet $E \wedge F = E \cap F$,
    \item events join $E \vee F = \text{cl}_\mathcal L (E \cup F)$,
\end{itemize}
\begin{proposition}[$\mathcal L$ is a orthomodular lattice]
    The event structure $mathcal L$, generated by all frame embeddings in the joint frame
    is an orthomodular lattice. Each frame embeds as a maximal Boolean subalgebra of 
    $\mathcal L$. Contextuality is exactly the failure of distributivity in $\mathcal  L$
    and what makes it orthomodular.
\end{proposition}
\begin{proof}
\end{proof}
\subsubsection*{The Hilbert Space}
Under the usual regularity assumptions on $\mathcal L$, the standard representation theorems
of quantum logic apply (e.g \cite{Piron}, \cite{Soler}, \cite{Gleason}). 
Therefore there exists a Hilbert space $\mathcal H$ and a lattice
isomorphism.
\[\mathcal L \cong \mathsf{Proj}(\mathcal H)\]
\subsubsection*{The Pointer Algebra}
Each frame corresponds to a maximal commuting family of projections in $\mathcal H$. The
pointer algebra $\mathcal F_\text{ptr}$ becomes the lattice of projections associated with
a single classical basis (a maximal distributive subalgebra). 

Thus the pointer corresponds to the diagonal projections in a distinguished basis, the 
pointer basis.
\subsubsection*{States in the Hilbert Space}
Since $\mathcal L$ carries empirical probability measures representing the pushfoward
from the frames preparations as we done previously, Gleanson's theorem \cite{Gleanson}
implies that each measure corresponds uniquely to a density operator $\rho$ on $\mathcal H$.

The born rule then, as we have seen appears as the familiar trace rule:
\[
    tr(\rho E_B) = \rho(E_b)
\]
\section{Dynamics}
In this version of the framework, dynamics is not introduced as a primitive law like a 
Hamiltonian flow or differential equation. Instead, dynamics arises from the structure
of interactions between information frames.

Each interaction between contexts induces:
\begin{itemize}
    \item A creation of a joint frame,
    \item followed by collapse to its pointer algebra,
    \item and a pushfoward updated of the preparation measure.
\end{itemize}
Thus, from a fixed frame point of view, the time evolution of it's description of the world
is simply a sequence of coarse-grained $\sigma$-algebras obtained from sucessive interations,
effectively a filtration:
\[
    \mathcal F_\text{frame} =: \mathcal F_0 \supseteq 
    \mathcal F_1 \supseteq \mathcal F_2 \supseteq ... \supseteq \mathcal F_n \supseteq ...
\]
This point of view makes several dynamical properties appear naturally:
\begin{enumerate}
    \item Arrow of Time

        Because each contextual interaction corresponds to additional coarse-graining,
        the evolution of $\sigma$-algebras is monotone (information losing). This
        monotonicity defines a natural direction of time.
    \item Locality Graph

        Interactions occur only between specific frames. The pattern of which frame couples
        to which determines a graph structure, which plays the role of space locality.
    \item Maximum Speed of Influence

        In contextual scenarios, incompatibility forces coarse-graining. The maximal number
        of interaction steps before contextuality appears bounds how "fast" influence can
        propagate along the locality graph.
    \item Markovianity

        Since each update depends only on the current $\sigma$-algebra and the new 
        interaction, the evolution is Markovian with respect to the filtrations of pointer
        algebras.
    \item No Signaling

        Because interactions only merge $\sigma$-algebras along edges of the locality graph,
        and collapse happens locally on the joint frame, no frame can influence another 
        without a mediated interaction.
\end{enumerate}
None of these dynamical features require any additional axioms. They follow from Axiom~1 
and the definitions of how interactions are built.
\subsection{Arrow of Time}
In this framework, time is not an external parameter. Instead we use the ordering of 
interactions between information frames to induce a canonical direction: each interaction
generates a joint frame where the initial frame algebra is embedded, collapse forces a
coarse graining of its algebra, this monotone loss of distinguishability defines a 
natural arrow of time for that frame.
\subsubsection*{Interaction-induced evolution of $\sigma$-algebras}
To begin, we first fix a information frame $\mathscr I_0$. It then proceeds to interact
with several frames $\mathscr I_{j_1}, \mathscr I_{j_2}$ and so on. 

At each step, a joint frame is first created to host the interaction, Axiom~1 and the 
collapse theorem then converge into a physically realizable joint frame with a sigma algebra
\[
    \mathcal F_{\mathcal J_n}^{\text{ptr}}
\]
That is, the pointer frame on the $n$-th joint frame. Since this is always constructed
by embedding the original $\sigma$-algebra $\mathcal F_0$, we can track its evolution
along the interactions.

We can look at the events of $\mathcal F_0$ that survive in the pointer frame 
$\mathcal F_{\mathcal J_1}^\text{ptr}$ as the $\sigma$-algebra of $\mathscr I_0$ at step
1. That is:
\[
    \mathcal F_1 := \mathcal F_{\mathcal J_1}^\text{ptr} \cap \iota_1(\mathcal F_0)
\]
This gives a natural sequence:
\[
    \mathcal F_0 \supseteq \mathcal F_1\supseteq \mathcal F_1 \supseteq ...
\]
Each step removes events that are incompatible with the new join. The future 
$\sigma$-algebras representations of $\mathcal F_0$ are strictly coarser algebras. There
is no way physical way in the framework to restore the lost distinctions.
\subsection{Locality Graph}
In this theory, \textbf{locality} is not a geometric primitive yet. It is the combinatorial
structure that records which frames have interacted and must therefore share a joint
pointer algebra.
\subsubsection*{The Locality Graph}
Let $\left\{\mathscr I_i\right\}_{i \in I}$ be a family of relevant information frames. We
define the graph:
\[
    G = (V,E)
\]
\[
    (i,j) \in E \quad \iff \quad \text{frames }\mathscr I_i \text{ and } \mathscr I_j
    \text{ have interacted.}
\]
And at every point, an edge represents there is a joint frame where the collapse has
taken place between $(i,j) \in E$.
\subsubsection*{Locality as constraint on the pointer basis}
If frames $i$ and $j$ have interacted, then their local projections $e_i$ and $e_j$ both
act on the same joint frame. Namely the pointer basis there must satisfy:
\[
    \mathcal F_\text{ptr} \subseteq \text{Fix}(e_i)\cap \text{Fix}(e_j)
\]
And if they have not interacted their projetions do not constrain the same $\sigma$-algebra,
which means:
\begin{itemize}
    \item Frames in the same subgraph in $G$ influence one another through constraints in
        the same pointer algebra
    \item Frames in different subgraphs remain completely independent. No constraints 
        propagate between them.
\end{itemize}
This reproduces the operational notion of locality, influence propagates only along paths in
the interaction graph.
\subsubsection*{Dynamics respects the locality graph}
When a new interaction occurs between frames $i$ and $j$ we:
\begin{enumerate}
    \item add an edge $(i,j)$ to $G$;
    \item build the joint frame of all contexts in the connected component containing $i$ 
        and $j$
    \item collapse using all local projections in that component.
\end{enumerate}
Therefore every subgraph of $G$ behaves as local regions, every interaction affects only 
the $\sigma$-algebra generated by its own components.

Locality therefore appears as:
\begin{itemize}
    \item graph locality where edges are interactions
    \item probabilistic locality conditional expectations factor across components of the
        sub graph
\end{itemize}
\subsubsection*{Intrepretation}
This provides a structural notion of spacetime locality:
\begin{itemize}
    \item Information frames as "positions".
    \item Interactions as "lightlike" adjacency.
    \item Paths in G are the only channels through which constraints can propagate.
\end{itemize} 
There is no geometry at this stage, geometry would be additional structure placed on top
of the locality graph.

We emphasize that "locality" and "time" in this theory are entirely structural notions.
They arise from the patterns of interactions between frames, not from any pre-assumed 
geometric spacetime. Any system that can be expressed through interacting information frames
possesses a well-defined locality graph and a induced temporal order, even when no 
traditional spacetime background is specified.
\subsection{Maximum Speed}
In this framework, influence can propagate only through interactions between frames, and
such interactions are encoded by edges in the locality graph $G$.

However contextuality imposes an additional constraint: after a sufficiently long chain
of interactions on mixed degrees of freedom, contextual incompatibility nescessarely appears.
Forcing a coarse-graining of the joint $\sigma$-algebra. This defines a \textbf{time step},
the length of the chain in that time step is always bounded by contextuality.
\subsubsection*{Contextuality forces coarse-graining}
A fundamental structural fact of contextuality (\cite{Abramsky&Brandenburger}) is that
for a sufficiently large family of information frames on shared degrees of freedom, their
combined $\sigma$-algebra on the joint frame cannot remain non-contextual.

While this is not a formal statement, as we could stay replaying interactions on 
non-contextual frames, in realistic scenarios contextuality will show up. At such step,
the pointer algebra will nescessarly coarse grain for some frame. That frame then sees
the length of the chain over the time step as the first interaction step.

Over several interactions, such chains which are always finite, have varying length. But 
any such interaction will have a finite upper bound.
\subsubsection*{Maximum speed for frame $i$}
Once we fix a frame $i$ we see its interaction path in $G$ as:
\[
    i = i_0 \rightarrow i_1 \rightarrow ... \rightarrow i_n = j
\]
In the step $i_n$ is when the first coarse graining happens. We can then define:
\[
    v_i := \sup {n: \mathcal F_n = \mathcal F_0}
\]
That is, the largest number of sequential interactions along which the $\sigma$-algebra of
$i$ remains untouched.
\subsubsection*{Intrepetation}
This pehnomenon should not be interpreted as the emergence of a specific relativistic sped
such as a "speed of light". It is a structural consequence of contextuality: in any 
sufficiently rich system of interacting information frames, repeated interactions inevitably 
produce contextual incompatibilities, which force coarse-graining and thereby prevent
influence from propagating indefinitely without degradation.

The resulting bound is a maximum interaction speed inherent to the information structure
itself. Although different contexts may have different local bounds, a common finite upper
bound always exists for any fixed system.
\subsection{Markovianity of interactions}
The evolution of descriptions in this theory is automatically \textbf{Markovian}. This
follows directly from the construction of the joint frames and Axiom~1, without introducing
any dynamical postulate or time parameter.
\subsubsection*{Dynamics depends only on the current $\sigma$-algebra}
At interaction step $n$, all previously interacting frames have already been incorporated
into the join pointer algebra $\mathcal F_n$.

The next interaction introduces a new local projection $e_{n+1}$ and the updated pointer
algebra is obtained by:
\[
    \mathcal F_{n+1} = \mathcal F_n \cap \text{Fix}(e_{n+1})
\]
Therefore the update rule is a \textbf{functional of the present state only}:
\[
    \mathcal F_{n+1} = \Phi(\mathcal F_n, e_{n+1})
\]
This is the essence of Markovianity.
\subsubsection*{Collapse erases historical information}
Becase each collapse step forces consistency with the new interacting context:
\begin{itemize}
    \item Any information that is incompatible with $\text{Fix}(e_{n+1})$ is erased.
    \item Any information already compatible with $\mathcal F_{n+1}$ is retained.
\end{itemize}
This makes evolution memoryless with respect to earlier algebras, there is no operational
quantity that distinguishes two histories that produce the same $\mathcal F_n$.

Therefore, once the current $\sigma$-algebra is known, the entire past becomes irrelevant.
All future predictions depend only on $\mathcal F_n$.
\subsubsection*{Intrepretation}
Markovianity in this framework is not a dynamical approximation or assumption about
noise. It is a structural consequence of:
\begin{enumerate}
    \item Interaction-driven enlargement of frames.
    \item Axiom~1 forcing coarse-graining.
    \item The shrinkage of $\sigma$-algebras that eliminates all incompatible distinctions.
\end{enumerate}
Therefore the evolution of knowledge in this theory is inherently Markovian because every
interaction erases all incompatible distinctions, leaving the current $\sigma$-algebra as
a complete description of everything that can influence the system on that frame.

That however, does not mean the probability structure is Markovian. Probability depend
on the outcomes reported, as we have seen in the measurement section. 
If a measurement was performed in a given basis, the further interactions carry the 
memory of the outcome. The algebras are conditioned on that previous outcome.
\subsection{No Signaling}
No signaling is an immediate structural consequence of the locality graph and Axiom~1. 
Because interactions are encoded as edges in the graph, and Axiom~1 applies only on the 
joint frames of the interacting frames, no frame can influence another without a path
of interaction connecting them.
\subsubsection*{Local Independence}
Let $i$ and $j$ represent two frames. If they have never interacted, they lie on different
subgraphs of $G$. Then no local projection $e_i$ of $i$ acts on any algebra observed by $j$.

Thus any mutual time step between then leaves $\mathcal F_j$ untouched, that is:
\[
    \mathcal F_j^{n+1} = \mathcal F_j^n
\]
When that time step operates on $i$, quite simply that is, a frame cannot alter the algebra
of a frame unless they interact.
\subsubsection*{Causal Separation}
If $i$ and $j$ lie in different subgraphs, let $e_k$ bet the local projection of a new
interaction on the subgraph of $i$. Since there is no path from $k$ to $j$ the projection
$e_k$ has no overlap with the algebras $j$ can see. Therefore, $e_k$ has no effect on 
$\mathcal F_j$.

Therefore
\begin{itemize}
    \item Effects of interactions propagate only along paths in the locality graph.
    \item Only frames lying in the same subgraph can influence each other.
\end{itemize}
This is a purely structural notion of causal separation.
\subsubsection*{Intrepretation}
No signaling in this framework is almost tautological, information cannot be transmitted 
between frames that have not interacted.
\section{Intrepetation and Comparisons}
Here we explore the theory in the context of the broader literature on measurement and
study some of its features, including the implications it has on ontology. We begin with
a informal example of the framework applied to the spin of a electron. To illustrate
how this framework maps to standard Quantum Mechanics.
\subsection{Spin Example}
Consdier a concreate quantum scenario, that of a single spin-$\frac{1}{2}$ system.

We examine two incompatible measurements:
\begin{itemize}
    \item $\mathscr I_z$: spin along the $z$-axis.
    \item $\mathscr I_x$: spin along the $x$-axis.
\end{itemize}
Each frame is represented by a two-outcome algebra:
\[
    \mathcal F_z = \left\{\emptyset,\{\uparrow_z\},\{\downarrow_z\}, \Omega_z\right\} \quad
    \mathcal F_x = \left\{\emptyset,\{\uparrow_x\},\{\downarrow_x\}, \Omega_x\right\}
\]
These are Boolean $\sigma$-algebras describen the events accessible to measurements in their
respective basis.

We begin with a free particle $\mathscr I_{\text{part}}$. This particle makes no 
distinctions about its own internal spin. So for this experiment, its algebra is considered
trivial.

The particle then interacts first with $\mathscr I_x$. This generates a joint frame where
the interaction can take place with algebra exactly:
\[
    \mathcal F_1^{\text{ptr}} = \mathcal F_x = \left\{\emptyset,\{\uparrow_x\},
    \{\downarrow_x\}, \Omega_x\right\}
\]
The observable is sampled there and obtains event $\uparrow_x$. Then the structure of the
joint frame is conditioned on this event. That is, the actual state is:
\[
    \mathcal F_1\mid \{\uparrow_x\} := \left\{E \cap \{\uparrow_x\}: E \in 
    \mathcal F_1\right\}
\]
Then, if we were to measure again on the same basis, this encodes running the same 
observable on the joint space. The only possibility in the restricted algebra is 
$\uparrow_x$.

Intuitively, the frame saw $\uparrow$ so the events, even in the measurement apparatus 
frame are conditioned on $\{\uparrow_x\}$. Now a new apparatus $\mathscr I_z$ comes and 
interacts with the system.

That leads to a new joint frame being built, and a new pointer basis, but here the 
observables are contextual so the pointer basis is given by:
\[
    \mathcal F_2^{\text{ptr}} = \text{Fix}(e_z)\cap\text{Fix}(e_x)
\]
But this pointer algebra is still conditioned on $\{\uparrow_x\}$. So effectively the state
is:
\[
    \mathcal F_2^{\text{ptr}} \mid \{\uparrow_x\}
\]
The Hilbert space representation of the spin-$x$ on the basis of $z$ show that there are
events that surive the $z$ measurement in the pointer basis. Furthermore the fact that the
algebra is conditioned on $\{\uparrow_x\}$ means we get:
\[
    \uparrow_z \quad \text{ with probability } \quad \frac{1}{2}
\]
\[
    \downarrow_z \quad \text{ with probability } \quad \frac{1}{2}
\]
Whatever outcome we get here, will again condition $\mathcal F_2^{\text{ptr}}$. If we measure
again on $z$ we will only be able to get definite outcomes.

But if we were to measure on $x$ on the joint frame conditioned on the event 
$\{\uparrow_x\}$ there would be two possible outcomes, with probability defined by the 
$z$ basis.
\subsection{The Ontology of Information Frames}
\subsection{Comparisons - Collapse Models}
\subsection{Comparisons - Intrepetations}
\section{Discussion}
\subsection{The Hilbert Space Reconstruction}
It is well known that the contextual space, here the joint frame, form a boolean lattice
that recovers most of the properties of a Hilbert Space. 

This view gives us a additional tool, mainly the automorphisms or the idea that, when a 
event must collpase down to a coarse grained version it picks up a phase, representing 
all the distinctions it could have held that map down to the same event. That might allow
us to get the complex field.

The rest of the reconstruction should already have precedent with contextuality frameworks.
\subsection{The Fisher metric view}
By taking the Markov view in section 5.5 we can explore this framework from the point of
view of the fisher metric. When contextuality happens, the ricci curvature of the fisher
metric blows up. That should trigger a back action on the tensor to adjust for the pointer
basis.

Known derivations of the schrodiger equation using the quantum fisher metric can be explained
and made canonical with this framework.

Furthermore, one can define a action principle of interactions. Using information geometry,
we believe that can give a new way to model physical systems.
\section{Conclusion}

\phantomsection
\addcontentsline{toc}{section}{References}
\begin{thebibliography}{9}

\bibitem{Williams1991}
D. Williams,  
\textit{Probability with Martingales},  
Cambridge University Press, 1991.

\bibitem{Pollard2002}
D. Pollard,  
\textit{A User’s Guide to Measure-Theoretic Probability},  
Cambridge University Press, 2002. 
\bibitem{Kallenberg}
O. Kallenberg,  
\textit{Foundations of Modern Probability},  
Springer, 2002.
\bibitem{Csiszar}
I. Csiszár,
\textit{Information-type measures of difference of probability distributions and indirect observation},  
Studia Sci. Math. Hungarica, 1967.

\end{thebibliography}
\end{document}

